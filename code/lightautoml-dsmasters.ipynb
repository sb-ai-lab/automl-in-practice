{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "subtle-tampa",
   "metadata": {
    "papermill": {
     "duration": 0.024153,
     "end_time": "2021-04-24T12:28:56.924027",
     "exception": false,
     "start_time": "2021-04-24T12:28:56.899874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 0.0. Install LightAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-zimbabwe",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-24T12:28:56.997332Z",
     "iopub.status.busy": "2021-04-24T12:28:56.984128Z",
     "iopub.status.idle": "2021-04-24T12:29:19.019206Z",
     "shell.execute_reply": "2021-04-24T12:29:19.018096Z"
    },
    "papermill": {
     "duration": 22.070557,
     "end_time": "2021-04-24T12:29:19.019390",
     "exception": false,
     "start_time": "2021-04-24T12:28:56.948833",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-typing",
   "metadata": {
    "papermill": {
     "duration": 0.054618,
     "end_time": "2021-04-24T12:29:19.135055",
     "exception": false,
     "start_time": "2021-04-24T12:29:19.080437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 0.1. Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "antique-armenia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:19.251419Z",
     "iopub.status.busy": "2021-04-24T12:29:19.249005Z",
     "iopub.status.idle": "2021-04-24T12:29:26.929120Z",
     "shell.execute_reply": "2021-04-24T12:29:26.929619Z"
    },
    "papermill": {
     "duration": 7.740526,
     "end_time": "2021-04-24T12:29:26.929845",
     "exception": false,
     "start_time": "2021-04-24T12:29:19.189319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard python libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.utils.profiler import Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-surge",
   "metadata": {
    "papermill": {
     "duration": 0.05406,
     "end_time": "2021-04-24T12:29:27.038613",
     "exception": false,
     "start_time": "2021-04-24T12:29:26.984553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 0.2. Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smoking-greene",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:27.153560Z",
     "iopub.status.busy": "2021-04-24T12:29:27.152920Z",
     "iopub.status.idle": "2021-04-24T12:29:27.156043Z",
     "shell.execute_reply": "2021-04-24T12:29:27.155399Z"
    },
    "papermill": {
     "duration": 0.062625,
     "end_time": "2021-04-24T12:29:27.156178",
     "exception": false,
     "start_time": "2021-04-24T12:29:27.093553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_THREADS = 4 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 1800 # Time in seconds for automl run\n",
    "TARGET = 'loan_default' # Target column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-sight",
   "metadata": {
    "papermill": {
     "duration": 0.053838,
     "end_time": "2021-04-24T12:29:27.264661",
     "exception": false,
     "start_time": "2021-04-24T12:29:27.210823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 0.3. Fix torch number of threads and numpy seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appreciated-johnston",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:27.378979Z",
     "iopub.status.busy": "2021-04-24T12:29:27.378207Z",
     "iopub.status.idle": "2021-04-24T12:29:27.380889Z",
     "shell.execute_reply": "2021-04-24T12:29:27.381372Z"
    },
    "papermill": {
     "duration": 0.061977,
     "end_time": "2021-04-24T12:29:27.381541",
     "exception": false,
     "start_time": "2021-04-24T12:29:27.319564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-calvin",
   "metadata": {
    "papermill": {
     "duration": 0.054964,
     "end_time": "2021-04-24T12:29:27.491894",
     "exception": false,
     "start_time": "2021-04-24T12:29:27.436930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 0.4. Data load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seven-dairy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:27.604002Z",
     "iopub.status.busy": "2021-04-24T12:29:27.603335Z",
     "iopub.status.idle": "2021-04-24T12:29:28.845071Z",
     "shell.execute_reply": "2021-04-24T12:29:28.844540Z"
    },
    "papermill": {
     "duration": 1.298857,
     "end_time": "2021-04-24T12:29:28.845216",
     "exception": false,
     "start_time": "2021-04-24T12:29:27.546359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 756 ms, sys: 110 ms, total: 866 ms\n",
      "Wall time: 1.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Date.of.Birth</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>DisbursalDate</th>\n",
       "      <th>State_ID</th>\n",
       "      <th>Employee_code_ID</th>\n",
       "      <th>MobileNo_Avl_Flag</th>\n",
       "      <th>Aadhar_flag</th>\n",
       "      <th>PAN_flag</th>\n",
       "      <th>VoterID_flag</th>\n",
       "      <th>Driving_flag</th>\n",
       "      <th>Passport_flag</th>\n",
       "      <th>PERFORM_CNS.SCORE</th>\n",
       "      <th>PERFORM_CNS.SCORE.DESCRIPTION</th>\n",
       "      <th>PRI.NO.OF.ACCTS</th>\n",
       "      <th>PRI.ACTIVE.ACCTS</th>\n",
       "      <th>PRI.OVERDUE.ACCTS</th>\n",
       "      <th>PRI.CURRENT.BALANCE</th>\n",
       "      <th>PRI.SANCTIONED.AMOUNT</th>\n",
       "      <th>PRI.DISBURSED.AMOUNT</th>\n",
       "      <th>SEC.NO.OF.ACCTS</th>\n",
       "      <th>SEC.ACTIVE.ACCTS</th>\n",
       "      <th>SEC.OVERDUE.ACCTS</th>\n",
       "      <th>SEC.CURRENT.BALANCE</th>\n",
       "      <th>SEC.SANCTIONED.AMOUNT</th>\n",
       "      <th>SEC.DISBURSED.AMOUNT</th>\n",
       "      <th>PRIMARY.INSTAL.AMT</th>\n",
       "      <th>SEC.INSTAL.AMT</th>\n",
       "      <th>NEW.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50578</td>\n",
       "      <td>58400</td>\n",
       "      <td>89.55</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1441</td>\n",
       "      <td>01-01-84</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>03-08-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47145</td>\n",
       "      <td>65550</td>\n",
       "      <td>73.23</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1502</td>\n",
       "      <td>31-07-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>26-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598</td>\n",
       "      <td>I-Medium Risk</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27600</td>\n",
       "      <td>50200</td>\n",
       "      <td>50200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53278</td>\n",
       "      <td>61360</td>\n",
       "      <td>89.63</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>24-08-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>01-08-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57513</td>\n",
       "      <td>66113</td>\n",
       "      <td>88.48</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1501</td>\n",
       "      <td>30-12-93</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>26-10-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>L-Very High Risk</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 8mon</td>\n",
       "      <td>1yrs 3mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52378</td>\n",
       "      <td>60300</td>\n",
       "      <td>88.39</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1495</td>\n",
       "      <td>09-12-77</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>26-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0             50578       58400  89.55         67        22807   \n",
       "1             47145       65550  73.23         67        22807   \n",
       "2             53278       61360  89.63         67        22807   \n",
       "3             57513       66113  88.48         67        22807   \n",
       "4             52378       60300  88.39         67        22807   \n",
       "\n",
       "   manufacturer_id  Current_pincode_ID Date.of.Birth Employment.Type  \\\n",
       "0               45                1441      01-01-84        Salaried   \n",
       "1               45                1502      31-07-85   Self employed   \n",
       "2               45                1497      24-08-85   Self employed   \n",
       "3               45                1501      30-12-93   Self employed   \n",
       "4               45                1495      09-12-77   Self employed   \n",
       "\n",
       "  DisbursalDate  State_ID  Employee_code_ID  MobileNo_Avl_Flag  Aadhar_flag  \\\n",
       "0      03-08-18         6              1998                  1            1   \n",
       "1      26-09-18         6              1998                  1            1   \n",
       "2      01-08-18         6              1998                  1            1   \n",
       "3      26-10-18         6              1998                  1            1   \n",
       "4      26-09-18         6              1998                  1            1   \n",
       "\n",
       "   PAN_flag  VoterID_flag  Driving_flag  Passport_flag  PERFORM_CNS.SCORE  \\\n",
       "0         0             0             0              0                  0   \n",
       "1         0             0             0              0                598   \n",
       "2         0             0             0              0                  0   \n",
       "3         0             0             0              0                305   \n",
       "4         0             0             0              0                  0   \n",
       "\n",
       "  PERFORM_CNS.SCORE.DESCRIPTION  PRI.NO.OF.ACCTS  PRI.ACTIVE.ACCTS  \\\n",
       "0   No Bureau History Available                0                 0   \n",
       "1                 I-Medium Risk                1                 1   \n",
       "2   No Bureau History Available                0                 0   \n",
       "3              L-Very High Risk                3                 0   \n",
       "4   No Bureau History Available                0                 0   \n",
       "\n",
       "   PRI.OVERDUE.ACCTS  PRI.CURRENT.BALANCE  PRI.SANCTIONED.AMOUNT  \\\n",
       "0                  0                    0                      0   \n",
       "1                  1                27600                  50200   \n",
       "2                  0                    0                      0   \n",
       "3                  0                    0                      0   \n",
       "4                  0                    0                      0   \n",
       "\n",
       "   PRI.DISBURSED.AMOUNT  SEC.NO.OF.ACCTS  SEC.ACTIVE.ACCTS  SEC.OVERDUE.ACCTS  \\\n",
       "0                     0                0                 0                  0   \n",
       "1                 50200                0                 0                  0   \n",
       "2                     0                0                 0                  0   \n",
       "3                     0                0                 0                  0   \n",
       "4                     0                0                 0                  0   \n",
       "\n",
       "   SEC.CURRENT.BALANCE  SEC.SANCTIONED.AMOUNT  SEC.DISBURSED.AMOUNT  \\\n",
       "0                    0                      0                     0   \n",
       "1                    0                      0                     0   \n",
       "2                    0                      0                     0   \n",
       "3                    0                      0                     0   \n",
       "4                    0                      0                     0   \n",
       "\n",
       "   PRIMARY.INSTAL.AMT  SEC.INSTAL.AMT  NEW.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
       "0                   0               0                             0   \n",
       "1                1991               0                             0   \n",
       "2                   0               0                             0   \n",
       "3                  31               0                             0   \n",
       "4                   0               0                             0   \n",
       "\n",
       "   DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS AVERAGE.ACCT.AGE CREDIT.HISTORY.LENGTH  \\\n",
       "0                                    0        0yrs 0mon             0yrs 0mon   \n",
       "1                                    1       1yrs 11mon            1yrs 11mon   \n",
       "2                                    0        0yrs 0mon             0yrs 0mon   \n",
       "3                                    0        0yrs 8mon             1yrs 3mon   \n",
       "4                                    0        0yrs 0mon             0yrs 0mon   \n",
       "\n",
       "   NO.OF_INQUIRIES  loan_default  \n",
       "0                0             0  \n",
       "1                0             1  \n",
       "2                0             0  \n",
       "3                1             1  \n",
       "4                1             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pd.set_option('display.max_columns', 100)\n",
    "train_data = pd.read_csv('../input/ds-masters-math-retake/default_train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "voluntary-taiwan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:28.961757Z",
     "iopub.status.busy": "2021-04-24T12:29:28.960948Z",
     "iopub.status.idle": "2021-04-24T12:29:29.128620Z",
     "shell.execute_reply": "2021-04-24T12:29:29.129152Z"
    },
    "papermill": {
     "duration": 0.22845,
     "end_time": "2021-04-24T12:29:29.129374",
     "exception": false,
     "start_time": "2021-04-24T12:29:28.900924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Date.of.Birth</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>DisbursalDate</th>\n",
       "      <th>State_ID</th>\n",
       "      <th>Employee_code_ID</th>\n",
       "      <th>MobileNo_Avl_Flag</th>\n",
       "      <th>Aadhar_flag</th>\n",
       "      <th>PAN_flag</th>\n",
       "      <th>VoterID_flag</th>\n",
       "      <th>Driving_flag</th>\n",
       "      <th>Passport_flag</th>\n",
       "      <th>PERFORM_CNS.SCORE</th>\n",
       "      <th>PERFORM_CNS.SCORE.DESCRIPTION</th>\n",
       "      <th>PRI.NO.OF.ACCTS</th>\n",
       "      <th>PRI.ACTIVE.ACCTS</th>\n",
       "      <th>PRI.OVERDUE.ACCTS</th>\n",
       "      <th>PRI.CURRENT.BALANCE</th>\n",
       "      <th>PRI.SANCTIONED.AMOUNT</th>\n",
       "      <th>PRI.DISBURSED.AMOUNT</th>\n",
       "      <th>SEC.NO.OF.ACCTS</th>\n",
       "      <th>SEC.ACTIVE.ACCTS</th>\n",
       "      <th>SEC.OVERDUE.ACCTS</th>\n",
       "      <th>SEC.CURRENT.BALANCE</th>\n",
       "      <th>SEC.SANCTIONED.AMOUNT</th>\n",
       "      <th>SEC.DISBURSED.AMOUNT</th>\n",
       "      <th>PRIMARY.INSTAL.AMT</th>\n",
       "      <th>SEC.INSTAL.AMT</th>\n",
       "      <th>NEW.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>52603</td>\n",
       "      <td>61300</td>\n",
       "      <td>86.95</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1492</td>\n",
       "      <td>01-06-68</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>16-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>A-Very Low Risk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1yrs 7mon</td>\n",
       "      <td>1yrs 7mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49478</td>\n",
       "      <td>57010</td>\n",
       "      <td>89.46</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>16-08-84</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>30-08-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "      <td>C-Very Low Risk</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>79750</td>\n",
       "      <td>187000</td>\n",
       "      <td>187000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1yrs 0mon</td>\n",
       "      <td>2yrs 1mon</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>53503</td>\n",
       "      <td>62100</td>\n",
       "      <td>87.28</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1498</td>\n",
       "      <td>27-02-83</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>20-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>688</td>\n",
       "      <td>E-Low Risk</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1076657</td>\n",
       "      <td>2277048</td>\n",
       "      <td>2277048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1yrs 10mon</td>\n",
       "      <td>4yrs 7mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70017</td>\n",
       "      <td>86760</td>\n",
       "      <td>82.99</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1479</td>\n",
       "      <td>10-08-88</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>06-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>585</td>\n",
       "      <td>I-Medium Risk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1yrs 9mon</td>\n",
       "      <td>1yrs 9mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50678</td>\n",
       "      <td>58300</td>\n",
       "      <td>89.88</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1474</td>\n",
       "      <td>01-06-77</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>14-08-18</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0   1             52603       61300  86.95         67        22807   \n",
       "1   2             49478       57010  89.46         67        22807   \n",
       "2   3             53503       62100  87.28         67        22807   \n",
       "3   4             70017       86760  82.99         67        22807   \n",
       "4   5             50678       58300  89.88         67        22807   \n",
       "\n",
       "   manufacturer_id  Current_pincode_ID Date.of.Birth Employment.Type  \\\n",
       "0               45                1492      01-06-68        Salaried   \n",
       "1               45                1497      16-08-84        Salaried   \n",
       "2               45                1498      27-02-83   Self employed   \n",
       "3               45                1479      10-08-88   Self employed   \n",
       "4               45                1474      01-06-77   Self employed   \n",
       "\n",
       "  DisbursalDate  State_ID  Employee_code_ID  MobileNo_Avl_Flag  Aadhar_flag  \\\n",
       "0      16-09-18         6              1998                  1            0   \n",
       "1      30-08-18         6              1998                  1            1   \n",
       "2      20-09-18         6              1998                  1            1   \n",
       "3      06-09-18         6              1998                  1            0   \n",
       "4      14-08-18         6              1998                  1            1   \n",
       "\n",
       "   PAN_flag  VoterID_flag  Driving_flag  Passport_flag  PERFORM_CNS.SCORE  \\\n",
       "0         0             1             0              0                818   \n",
       "1         0             0             0              0                738   \n",
       "2         0             0             0              0                688   \n",
       "3         0             1             0              0                585   \n",
       "4         0             0             0              0                  0   \n",
       "\n",
       "  PERFORM_CNS.SCORE.DESCRIPTION  PRI.NO.OF.ACCTS  PRI.ACTIVE.ACCTS  \\\n",
       "0               A-Very Low Risk                1                 0   \n",
       "1               C-Very Low Risk               10                 5   \n",
       "2                    E-Low Risk               13                 8   \n",
       "3                 I-Medium Risk                1                 0   \n",
       "4   No Bureau History Available                0                 0   \n",
       "\n",
       "   PRI.OVERDUE.ACCTS  PRI.CURRENT.BALANCE  PRI.SANCTIONED.AMOUNT  \\\n",
       "0                  0                    0                      0   \n",
       "1                  0                79750                 187000   \n",
       "2                  0              1076657                2277048   \n",
       "3                  1                    0                      0   \n",
       "4                  0                    0                      0   \n",
       "\n",
       "   PRI.DISBURSED.AMOUNT  SEC.NO.OF.ACCTS  SEC.ACTIVE.ACCTS  SEC.OVERDUE.ACCTS  \\\n",
       "0                     0                0                 0                  0   \n",
       "1                187000                0                 0                  0   \n",
       "2               2277048                0                 0                  0   \n",
       "3                     0                0                 0                  0   \n",
       "4                     0                0                 0                  0   \n",
       "\n",
       "   SEC.CURRENT.BALANCE  SEC.SANCTIONED.AMOUNT  SEC.DISBURSED.AMOUNT  \\\n",
       "0                    0                      0                     0   \n",
       "1                    0                      0                     0   \n",
       "2                    0                      0                     0   \n",
       "3                    0                      0                     0   \n",
       "4                    0                      0                     0   \n",
       "\n",
       "   PRIMARY.INSTAL.AMT  SEC.INSTAL.AMT  NEW.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
       "0                2608               0                             0   \n",
       "1               23309               0                             1   \n",
       "2                4982               0                             1   \n",
       "3                   0               0                             0   \n",
       "4                   0               0                             0   \n",
       "\n",
       "   DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS AVERAGE.ACCT.AGE CREDIT.HISTORY.LENGTH  \\\n",
       "0                                    0        1yrs 7mon             1yrs 7mon   \n",
       "1                                    0        1yrs 0mon             2yrs 1mon   \n",
       "2                                    0       1yrs 10mon             4yrs 7mon   \n",
       "3                                    0        1yrs 9mon             1yrs 9mon   \n",
       "4                                    0        0yrs 0mon             0yrs 0mon   \n",
       "\n",
       "   NO.OF_INQUIRIES  \n",
       "0                0  \n",
       "1                4  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../input/ds-masters-math-retake/default_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pleasant-mortgage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:29.248521Z",
     "iopub.status.busy": "2021-04-24T12:29:29.247794Z",
     "iopub.status.idle": "2021-04-24T12:29:29.269619Z",
     "shell.execute_reply": "2021-04-24T12:29:29.269004Z"
    },
    "papermill": {
     "duration": 0.082881,
     "end_time": "2021-04-24T12:29:29.269781",
     "exception": false,
     "start_time": "2021-04-24T12:29:29.186900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  loan_default\n",
       "0   1             1\n",
       "1   2             1\n",
       "2   3             1\n",
       "3   4             1\n",
       "4   5             1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/ds-masters-math-retake/default_sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-relevance",
   "metadata": {
    "papermill": {
     "duration": 0.057123,
     "end_time": "2021-04-24T12:29:29.384509",
     "exception": false,
     "start_time": "2021-04-24T12:29:29.327386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 0.5. Add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sexual-equation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:29.527179Z",
     "iopub.status.busy": "2021-04-24T12:29:29.526186Z",
     "iopub.status.idle": "2021-04-24T12:29:31.441123Z",
     "shell.execute_reply": "2021-04-24T12:29:31.440536Z"
    },
    "papermill": {
     "duration": 1.999333,
     "end_time": "2021-04-24T12:29:31.441278",
     "exception": false,
     "start_time": "2021-04-24T12:29:29.441945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_extra_features(data):\n",
    "    data['DatesDiff'] = (pd.to_datetime(data['DisbursalDate'], format = '%d-%m-%y') - \n",
    "                         pd.to_datetime(data['Date.of.Birth'], format = '%d-%m-%y')) / np.timedelta64(1, 'D')\n",
    "    data.drop(columns = ['DisbursalDate', 'Date.of.Birth'], inplace = True)\n",
    "    \n",
    "    for col in ['AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH']:\n",
    "        data[col + '_years'] = data[col].map(lambda x: x.split(' ')[0][:-3]).astype(int)\n",
    "        data[col + '_mons'] = data[col].map(lambda x: x.split(' ')[1][:-3]).astype(int)\n",
    "        data[col + '_full_num_mons'] = data[col + '_years'] * 12 + data[col + '_mons']\n",
    "        \n",
    "    data['diff_in_mons_num'] = data['CREDIT.HISTORY.LENGTH' + '_full_num_mons'] - data['AVERAGE.ACCT.AGE' + '_full_num_mons']\n",
    "    \n",
    "    data['CNS_score_type'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].map(lambda x: ord(x[0]) - ord('A'))\n",
    "    data['CNS_score_type_no_scored'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].map(\n",
    "                                            lambda x: x[:10] if x.startswith('Not Scored: ') else x)\n",
    "    \n",
    "\n",
    "create_extra_features(train_data)\n",
    "create_extra_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "funny-guard",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:31.615084Z",
     "iopub.status.busy": "2021-04-24T12:29:31.570623Z",
     "iopub.status.idle": "2021-04-24T12:29:31.621312Z",
     "shell.execute_reply": "2021-04-24T12:29:31.620747Z"
    },
    "papermill": {
     "duration": 0.120912,
     "end_time": "2021-04-24T12:29:31.621446",
     "exception": false,
     "start_time": "2021-04-24T12:29:31.500534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>State_ID</th>\n",
       "      <th>Employee_code_ID</th>\n",
       "      <th>MobileNo_Avl_Flag</th>\n",
       "      <th>Aadhar_flag</th>\n",
       "      <th>PAN_flag</th>\n",
       "      <th>VoterID_flag</th>\n",
       "      <th>Driving_flag</th>\n",
       "      <th>Passport_flag</th>\n",
       "      <th>PERFORM_CNS.SCORE</th>\n",
       "      <th>PERFORM_CNS.SCORE.DESCRIPTION</th>\n",
       "      <th>PRI.NO.OF.ACCTS</th>\n",
       "      <th>PRI.ACTIVE.ACCTS</th>\n",
       "      <th>PRI.OVERDUE.ACCTS</th>\n",
       "      <th>PRI.CURRENT.BALANCE</th>\n",
       "      <th>PRI.SANCTIONED.AMOUNT</th>\n",
       "      <th>PRI.DISBURSED.AMOUNT</th>\n",
       "      <th>SEC.NO.OF.ACCTS</th>\n",
       "      <th>SEC.ACTIVE.ACCTS</th>\n",
       "      <th>SEC.OVERDUE.ACCTS</th>\n",
       "      <th>SEC.CURRENT.BALANCE</th>\n",
       "      <th>SEC.SANCTIONED.AMOUNT</th>\n",
       "      <th>SEC.DISBURSED.AMOUNT</th>\n",
       "      <th>PRIMARY.INSTAL.AMT</th>\n",
       "      <th>SEC.INSTAL.AMT</th>\n",
       "      <th>NEW.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "      <th>loan_default</th>\n",
       "      <th>DatesDiff</th>\n",
       "      <th>AVERAGE.ACCT.AGE_years</th>\n",
       "      <th>AVERAGE.ACCT.AGE_mons</th>\n",
       "      <th>AVERAGE.ACCT.AGE_full_num_mons</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH_years</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH_mons</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH_full_num_mons</th>\n",
       "      <th>diff_in_mons_num</th>\n",
       "      <th>CNS_score_type</th>\n",
       "      <th>CNS_score_type_no_scored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50578</td>\n",
       "      <td>58400</td>\n",
       "      <td>89.55</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1441</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12633.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47145</td>\n",
       "      <td>65550</td>\n",
       "      <td>73.23</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1502</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598</td>\n",
       "      <td>I-Medium Risk</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27600</td>\n",
       "      <td>50200</td>\n",
       "      <td>50200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>I-Medium Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53278</td>\n",
       "      <td>61360</td>\n",
       "      <td>89.63</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12030.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57513</td>\n",
       "      <td>66113</td>\n",
       "      <td>88.48</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1501</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>L-Very High Risk</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 8mon</td>\n",
       "      <td>1yrs 3mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9066.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>L-Very High Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52378</td>\n",
       "      <td>60300</td>\n",
       "      <td>88.39</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1495</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14901.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209878</th>\n",
       "      <td>38439</td>\n",
       "      <td>52965</td>\n",
       "      <td>74.58</td>\n",
       "      <td>34</td>\n",
       "      <td>20700</td>\n",
       "      <td>48</td>\n",
       "      <td>1051</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>6</td>\n",
       "      <td>3705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "      <td>C-Very Low Risk</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7001</td>\n",
       "      <td>14839</td>\n",
       "      <td>14839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 3mon</td>\n",
       "      <td>0yrs 3mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13244.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C-Very Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209879</th>\n",
       "      <td>72623</td>\n",
       "      <td>105405</td>\n",
       "      <td>69.73</td>\n",
       "      <td>34</td>\n",
       "      <td>20700</td>\n",
       "      <td>48</td>\n",
       "      <td>1051</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>6</td>\n",
       "      <td>3705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>C-Very Low Risk</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>201422</td>\n",
       "      <td>276624</td>\n",
       "      <td>237977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 9mon</td>\n",
       "      <td>1yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10726.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>C-Very Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209880</th>\n",
       "      <td>42894</td>\n",
       "      <td>60334</td>\n",
       "      <td>72.93</td>\n",
       "      <td>34</td>\n",
       "      <td>20700</td>\n",
       "      <td>48</td>\n",
       "      <td>1051</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>6</td>\n",
       "      <td>3705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9239.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209881</th>\n",
       "      <td>73651</td>\n",
       "      <td>100600</td>\n",
       "      <td>74.95</td>\n",
       "      <td>34</td>\n",
       "      <td>23775</td>\n",
       "      <td>51</td>\n",
       "      <td>990</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>6</td>\n",
       "      <td>3705</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "      <td>A-Very Low Risk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 6mon</td>\n",
       "      <td>0yrs 6mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10914.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A-Very Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209882</th>\n",
       "      <td>33484</td>\n",
       "      <td>71212</td>\n",
       "      <td>48.45</td>\n",
       "      <td>77</td>\n",
       "      <td>22186</td>\n",
       "      <td>86</td>\n",
       "      <td>2299</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>4</td>\n",
       "      <td>3479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15485.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209883 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0                  50578       58400  89.55         67        22807   \n",
       "1                  47145       65550  73.23         67        22807   \n",
       "2                  53278       61360  89.63         67        22807   \n",
       "3                  57513       66113  88.48         67        22807   \n",
       "4                  52378       60300  88.39         67        22807   \n",
       "...                  ...         ...    ...        ...          ...   \n",
       "209878             38439       52965  74.58         34        20700   \n",
       "209879             72623      105405  69.73         34        20700   \n",
       "209880             42894       60334  72.93         34        20700   \n",
       "209881             73651      100600  74.95         34        23775   \n",
       "209882             33484       71212  48.45         77        22186   \n",
       "\n",
       "        manufacturer_id  Current_pincode_ID Employment.Type  State_ID  \\\n",
       "0                    45                1441        Salaried         6   \n",
       "1                    45                1502   Self employed         6   \n",
       "2                    45                1497   Self employed         6   \n",
       "3                    45                1501   Self employed         6   \n",
       "4                    45                1495   Self employed         6   \n",
       "...                 ...                 ...             ...       ...   \n",
       "209878               48                1051   Self employed         6   \n",
       "209879               48                1051        Salaried         6   \n",
       "209880               48                1051        Salaried         6   \n",
       "209881               51                 990   Self employed         6   \n",
       "209882               86                2299        Salaried         4   \n",
       "\n",
       "        Employee_code_ID  MobileNo_Avl_Flag  Aadhar_flag  PAN_flag  \\\n",
       "0                   1998                  1            1         0   \n",
       "1                   1998                  1            1         0   \n",
       "2                   1998                  1            1         0   \n",
       "3                   1998                  1            1         0   \n",
       "4                   1998                  1            1         0   \n",
       "...                  ...                ...          ...       ...   \n",
       "209878              3705                  1            1         0   \n",
       "209879              3705                  1            1         0   \n",
       "209880              3705                  1            1         0   \n",
       "209881              3705                  1            0         0   \n",
       "209882              3479                  1            1         0   \n",
       "\n",
       "        VoterID_flag  Driving_flag  Passport_flag  PERFORM_CNS.SCORE  \\\n",
       "0                  0             0              0                  0   \n",
       "1                  0             0              0                598   \n",
       "2                  0             0              0                  0   \n",
       "3                  0             0              0                305   \n",
       "4                  0             0              0                  0   \n",
       "...              ...           ...            ...                ...   \n",
       "209878             0             0              0                738   \n",
       "209879             0             0              0                755   \n",
       "209880             0             0              0                  0   \n",
       "209881             1             0              0                825   \n",
       "209882             0             0              0                  0   \n",
       "\n",
       "       PERFORM_CNS.SCORE.DESCRIPTION  PRI.NO.OF.ACCTS  PRI.ACTIVE.ACCTS  \\\n",
       "0        No Bureau History Available                0                 0   \n",
       "1                      I-Medium Risk                1                 1   \n",
       "2        No Bureau History Available                0                 0   \n",
       "3                   L-Very High Risk                3                 0   \n",
       "4        No Bureau History Available                0                 0   \n",
       "...                              ...              ...               ...   \n",
       "209878               C-Very Low Risk                2                 2   \n",
       "209879               C-Very Low Risk                4                 4   \n",
       "209880   No Bureau History Available                0                 0   \n",
       "209881               A-Very Low Risk                1                 0   \n",
       "209882   No Bureau History Available                0                 0   \n",
       "\n",
       "        PRI.OVERDUE.ACCTS  PRI.CURRENT.BALANCE  PRI.SANCTIONED.AMOUNT  \\\n",
       "0                       0                    0                      0   \n",
       "1                       1                27600                  50200   \n",
       "2                       0                    0                      0   \n",
       "3                       0                    0                      0   \n",
       "4                       0                    0                      0   \n",
       "...                   ...                  ...                    ...   \n",
       "209878                  0                 7001                  14839   \n",
       "209879                  0               201422                 276624   \n",
       "209880                  0                    0                      0   \n",
       "209881                  0                    0                      0   \n",
       "209882                  0                    0                      0   \n",
       "\n",
       "        PRI.DISBURSED.AMOUNT  SEC.NO.OF.ACCTS  SEC.ACTIVE.ACCTS  \\\n",
       "0                          0                0                 0   \n",
       "1                      50200                0                 0   \n",
       "2                          0                0                 0   \n",
       "3                          0                0                 0   \n",
       "4                          0                0                 0   \n",
       "...                      ...              ...               ...   \n",
       "209878                 14839                0                 0   \n",
       "209879                237977                0                 0   \n",
       "209880                     0                0                 0   \n",
       "209881                     0                0                 0   \n",
       "209882                     0                0                 0   \n",
       "\n",
       "        SEC.OVERDUE.ACCTS  SEC.CURRENT.BALANCE  SEC.SANCTIONED.AMOUNT  \\\n",
       "0                       0                    0                      0   \n",
       "1                       0                    0                      0   \n",
       "2                       0                    0                      0   \n",
       "3                       0                    0                      0   \n",
       "4                       0                    0                      0   \n",
       "...                   ...                  ...                    ...   \n",
       "209878                  0                    0                      0   \n",
       "209879                  0                    0                      0   \n",
       "209880                  0                    0                      0   \n",
       "209881                  0                    0                      0   \n",
       "209882                  0                    0                      0   \n",
       "\n",
       "        SEC.DISBURSED.AMOUNT  PRIMARY.INSTAL.AMT  SEC.INSTAL.AMT  \\\n",
       "0                          0                   0               0   \n",
       "1                          0                1991               0   \n",
       "2                          0                   0               0   \n",
       "3                          0                  31               0   \n",
       "4                          0                   0               0   \n",
       "...                      ...                 ...             ...   \n",
       "209878                     0                   0               0   \n",
       "209879                     0                   0               0   \n",
       "209880                     0                   0               0   \n",
       "209881                     0                1565               0   \n",
       "209882                     0                   0               0   \n",
       "\n",
       "        NEW.ACCTS.IN.LAST.SIX.MONTHS  DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
       "0                                  0                                    0   \n",
       "1                                  0                                    1   \n",
       "2                                  0                                    0   \n",
       "3                                  0                                    0   \n",
       "4                                  0                                    0   \n",
       "...                              ...                                  ...   \n",
       "209878                             2                                    0   \n",
       "209879                             1                                    0   \n",
       "209880                             0                                    0   \n",
       "209881                             0                                    0   \n",
       "209882                             0                                    0   \n",
       "\n",
       "       AVERAGE.ACCT.AGE CREDIT.HISTORY.LENGTH  NO.OF_INQUIRIES  loan_default  \\\n",
       "0             0yrs 0mon             0yrs 0mon                0             0   \n",
       "1            1yrs 11mon            1yrs 11mon                0             1   \n",
       "2             0yrs 0mon             0yrs 0mon                0             0   \n",
       "3             0yrs 8mon             1yrs 3mon                1             1   \n",
       "4             0yrs 0mon             0yrs 0mon                1             1   \n",
       "...                 ...                   ...              ...           ...   \n",
       "209878        0yrs 3mon             0yrs 3mon                0             0   \n",
       "209879        0yrs 9mon             1yrs 0mon                0             0   \n",
       "209880        0yrs 0mon             0yrs 0mon                0             0   \n",
       "209881        0yrs 6mon             0yrs 6mon                0             0   \n",
       "209882        0yrs 0mon             0yrs 0mon                0             0   \n",
       "\n",
       "        DatesDiff  AVERAGE.ACCT.AGE_years  AVERAGE.ACCT.AGE_mons  \\\n",
       "0         12633.0                       0                      0   \n",
       "1         12110.0                       1                     11   \n",
       "2         12030.0                       0                      0   \n",
       "3          9066.0                       0                      8   \n",
       "4         14901.0                       0                      0   \n",
       "...           ...                     ...                    ...   \n",
       "209878    13244.0                       0                      3   \n",
       "209879    10726.0                       0                      9   \n",
       "209880     9239.0                       0                      0   \n",
       "209881    10914.0                       0                      6   \n",
       "209882    15485.0                       0                      0   \n",
       "\n",
       "        AVERAGE.ACCT.AGE_full_num_mons  CREDIT.HISTORY.LENGTH_years  \\\n",
       "0                                    0                            0   \n",
       "1                                   23                            1   \n",
       "2                                    0                            0   \n",
       "3                                    8                            1   \n",
       "4                                    0                            0   \n",
       "...                                ...                          ...   \n",
       "209878                               3                            0   \n",
       "209879                               9                            1   \n",
       "209880                               0                            0   \n",
       "209881                               6                            0   \n",
       "209882                               0                            0   \n",
       "\n",
       "        CREDIT.HISTORY.LENGTH_mons  CREDIT.HISTORY.LENGTH_full_num_mons  \\\n",
       "0                                0                                    0   \n",
       "1                               11                                   23   \n",
       "2                                0                                    0   \n",
       "3                                3                                   15   \n",
       "4                                0                                    0   \n",
       "...                            ...                                  ...   \n",
       "209878                           3                                    3   \n",
       "209879                           0                                   12   \n",
       "209880                           0                                    0   \n",
       "209881                           6                                    6   \n",
       "209882                           0                                    0   \n",
       "\n",
       "        diff_in_mons_num  CNS_score_type     CNS_score_type_no_scored  \n",
       "0                      0              13  No Bureau History Available  \n",
       "1                      0               8                I-Medium Risk  \n",
       "2                      0              13  No Bureau History Available  \n",
       "3                      7              11             L-Very High Risk  \n",
       "4                      0              13  No Bureau History Available  \n",
       "...                  ...             ...                          ...  \n",
       "209878                 0               2              C-Very Low Risk  \n",
       "209879                 3               2              C-Very Low Risk  \n",
       "209880                 0              13  No Bureau History Available  \n",
       "209881                 0               0              A-Very Low Risk  \n",
       "209882                 0              13  No Bureau History Available  \n",
       "\n",
       "[209883 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-dylan",
   "metadata": {
    "papermill": {
     "duration": 0.058556,
     "end_time": "2021-04-24T12:29:31.739212",
     "exception": false,
     "start_time": "2021-04-24T12:29:31.680656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 0.6. Data splitting for train-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "periodic-affiliate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:31.866970Z",
     "iopub.status.busy": "2021-04-24T12:29:31.866278Z",
     "iopub.status.idle": "2021-04-24T12:29:32.220463Z",
     "shell.execute_reply": "2021-04-24T12:29:32.219884Z"
    },
    "papermill": {
     "duration": 0.421421,
     "end_time": "2021-04-24T12:29:32.220608",
     "exception": false,
     "start_time": "2021-04-24T12:29:31.799187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitted. Parts sizes: tr_data = (167906, 48), te_data = (41977, 48)\n"
     ]
    }
   ],
   "source": [
    "tr_data, te_data = train_test_split(train_data, \n",
    "                                     test_size=TEST_SIZE, \n",
    "                                     stratify=train_data[TARGET], \n",
    "                                     random_state=RANDOM_STATE)\n",
    "print('Data splitted. Parts sizes: tr_data = {}, te_data = {}'.format(tr_data.shape, te_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-platform",
   "metadata": {
    "papermill": {
     "duration": 0.062562,
     "end_time": "2021-04-24T12:29:32.344934",
     "exception": false,
     "start_time": "2021-04-24T12:29:32.282372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ========= AutoML preset usage =========\n",
    "\n",
    "\n",
    "## Step 1. Create Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affected-collaboration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:32.475848Z",
     "iopub.status.busy": "2021-04-24T12:29:32.475058Z",
     "iopub.status.idle": "2021-04-24T12:29:32.479233Z",
     "shell.execute_reply": "2021-04-24T12:29:32.478753Z"
    },
    "papermill": {
     "duration": 0.073913,
     "end_time": "2021-04-24T12:29:32.479381",
     "exception": false,
     "start_time": "2021-04-24T12:29:32.405468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.05 ms, sys: 0 ns, total: 3.05 ms\n",
      "Wall time: 2.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def acc_score(y_true, y_pred, **kwargs):\n",
    "    return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n",
    "\n",
    "task = Task('binary', metric = acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-packing",
   "metadata": {
    "papermill": {
     "duration": 0.059785,
     "end_time": "2021-04-24T12:29:32.600425",
     "exception": false,
     "start_time": "2021-04-24T12:29:32.540640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2. Setup columns roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "authorized-description",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:32.725674Z",
     "iopub.status.busy": "2021-04-24T12:29:32.724987Z",
     "iopub.status.idle": "2021-04-24T12:29:32.728335Z",
     "shell.execute_reply": "2021-04-24T12:29:32.728860Z"
    },
    "papermill": {
     "duration": 0.06855,
     "end_time": "2021-04-24T12:29:32.729024",
     "exception": false,
     "start_time": "2021-04-24T12:29:32.660474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 s, sys: 0 ns, total: 3 s\n",
      "Wall time: 7.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "roles = {\n",
    "    'target': TARGET\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-setup",
   "metadata": {
    "papermill": {
     "duration": 0.061423,
     "end_time": "2021-04-24T12:29:32.851269",
     "exception": false,
     "start_time": "2021-04-24T12:29:32.789846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3. Create AutoML from preset and train on 80% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "paperback-comparison",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-24T12:29:32.989943Z",
     "iopub.status.busy": "2021-04-24T12:29:32.989285Z",
     "iopub.status.idle": "2021-04-24T12:37:52.566236Z",
     "shell.execute_reply": "2021-04-24T12:37:52.565660Z"
    },
    "papermill": {
     "duration": 499.654411,
     "end_time": "2021-04-24T12:37:52.566388",
     "exception": false,
     "start_time": "2021-04-24T12:29:32.911977",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start automl preset with listed constraints:\n",
      "- time: 1800 seconds\n",
      "- cpus: 4 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (167906, 48)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 1767.6029913425446 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7826514204037878\n",
      "Linear model: C = 5e-05 score = 0.7830683104043833\n",
      "Linear model: C = 0.0001 score = 0.7829491989756417\n",
      "Linear model: C = 0.0005 score = 0.7830087546900125\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827938417557547\n",
      "Linear model: C = 5e-05 score = 0.783061850451148\n",
      "Linear model: C = 0.0001 score = 0.7835085316101367\n",
      "Linear model: C = 0.0005 score = 0.7836872040737322\n",
      "Linear model: C = 0.001 score = 0.7834489741222715\n",
      "Linear model: C = 0.005 score = 0.7834191953783389\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827938417557547\n",
      "Linear model: C = 5e-05 score = 0.7829129567314851\n",
      "Linear model: C = 0.0001 score = 0.7828533992436199\n",
      "Linear model: C = 0.0005 score = 0.782704505523957\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7826747267800244\n",
      "Linear model: C = 5e-05 score = 0.7826747267800244\n",
      "Linear model: C = 0.0001 score = 0.7825258330603615\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827342842678896\n",
      "Linear model: C = 5e-05 score = 0.7833298591465412\n",
      "Linear model: C = 0.0001 score = 0.7832703016586761\n",
      "Linear model: C = 0.0005 score = 0.783061850451148\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 1742.2220258712769\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.495703\tvalid's Opt metric: 0.783604\n",
      "[200]\tvalid's binary_logloss: 0.494865\tvalid's Opt metric: 0.783545\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid's binary_logloss: 0.49565\tvalid's Opt metric: 0.783902\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49181\tvalid's Opt metric: 0.783843\n",
      "[200]\tvalid's binary_logloss: 0.490764\tvalid's Opt metric: 0.784468\n",
      "[300]\tvalid's binary_logloss: 0.490398\tvalid's Opt metric: 0.784081\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid's binary_logloss: 0.490656\tvalid's Opt metric: 0.784795\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493399\tvalid's Opt metric: 0.783687\n",
      "[200]\tvalid's binary_logloss: 0.492842\tvalid's Opt metric: 0.783896\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid's binary_logloss: 0.492898\tvalid's Opt metric: 0.784223\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493793\tvalid's Opt metric: 0.783181\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid's binary_logloss: 0.494476\tvalid's Opt metric: 0.783628\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492734\tvalid's Opt metric: 0.783151\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid's binary_logloss: 0.495274\tvalid's Opt metric: 0.783538\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490823\tvalid's Opt metric: 0.783568\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid's binary_logloss: 0.491363\tvalid's Opt metric: 0.783985\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 1255.7953660488129 secs\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492348\tvalid's Opt metric: 0.783932\n",
      "[200]\tvalid's binary_logloss: 0.492012\tvalid's Opt metric: 0.784438\n",
      "[300]\tvalid's binary_logloss: 0.491965\tvalid's Opt metric: 0.784319\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid's binary_logloss: 0.491721\tvalid's Opt metric: 0.784587\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492057\tvalid's Opt metric: 0.783753\n",
      "[200]\tvalid's binary_logloss: 0.491055\tvalid's Opt metric: 0.784766\n",
      "[300]\tvalid's binary_logloss: 0.490879\tvalid's Opt metric: 0.784944\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid's binary_logloss: 0.490737\tvalid's Opt metric: 0.785361\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492312\tvalid's Opt metric: 0.78417\n",
      "[200]\tvalid's binary_logloss: 0.490958\tvalid's Opt metric: 0.784438\n",
      "[300]\tvalid's binary_logloss: 0.490826\tvalid's Opt metric: 0.784557\n",
      "[400]\tvalid's binary_logloss: 0.490834\tvalid's Opt metric: 0.784527\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid's binary_logloss: 0.490748\tvalid's Opt metric: 0.784736\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492241\tvalid's Opt metric: 0.78414\n",
      "[200]\tvalid's binary_logloss: 0.490763\tvalid's Opt metric: 0.784706\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid's binary_logloss: 0.491166\tvalid's Opt metric: 0.784825\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492655\tvalid's Opt metric: 0.783962\n",
      "[200]\tvalid's binary_logloss: 0.492152\tvalid's Opt metric: 0.784617\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid's binary_logloss: 0.492073\tvalid's Opt metric: 0.784587\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492531\tvalid's Opt metric: 0.783932\n",
      "[200]\tvalid's binary_logloss: 0.491279\tvalid's Opt metric: 0.784795\n",
      "[300]\tvalid's binary_logloss: 0.490859\tvalid's Opt metric: 0.784498\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid's binary_logloss: 0.491257\tvalid's Opt metric: 0.785004\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492603\tvalid's Opt metric: 0.783485\n",
      "[200]\tvalid's binary_logloss: 0.491241\tvalid's Opt metric: 0.784766\n",
      "[300]\tvalid's binary_logloss: 0.490873\tvalid's Opt metric: 0.785123\n",
      "[400]\tvalid's binary_logloss: 0.490516\tvalid's Opt metric: 0.785063\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid's binary_logloss: 0.490567\tvalid's Opt metric: 0.785391\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493055\tvalid's Opt metric: 0.784081\n",
      "[200]\tvalid's binary_logloss: 0.493126\tvalid's Opt metric: 0.784676\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid's binary_logloss: 0.492685\tvalid's Opt metric: 0.784468\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49227\tvalid's Opt metric: 0.783515\n",
      "[200]\tvalid's binary_logloss: 0.490759\tvalid's Opt metric: 0.784676\n",
      "[300]\tvalid's binary_logloss: 0.490403\tvalid's Opt metric: 0.784587\n",
      "[400]\tvalid's binary_logloss: 0.49019\tvalid's Opt metric: 0.784825\n",
      "[500]\tvalid's binary_logloss: 0.489944\tvalid's Opt metric: 0.785034\n",
      "[600]\tvalid's binary_logloss: 0.489811\tvalid's Opt metric: 0.785212\n",
      "Early stopping, best iteration is:\n",
      "[584]\tvalid's binary_logloss: 0.489781\tvalid's Opt metric: 0.785153\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492286\tvalid's Opt metric: 0.784289\n",
      "[200]\tvalid's binary_logloss: 0.492576\tvalid's Opt metric: 0.784647\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid's binary_logloss: 0.491961\tvalid's Opt metric: 0.784051\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494459\tvalid's Opt metric: 0.783068\n",
      "[200]\tvalid's binary_logloss: 0.492365\tvalid's Opt metric: 0.783872\n",
      "[300]\tvalid's binary_logloss: 0.491996\tvalid's Opt metric: 0.783991\n",
      "[400]\tvalid's binary_logloss: 0.491796\tvalid's Opt metric: 0.784021\n",
      "[500]\tvalid's binary_logloss: 0.491521\tvalid's Opt metric: 0.784081\n",
      "Early stopping, best iteration is:\n",
      "[459]\tvalid's binary_logloss: 0.491628\tvalid's Opt metric: 0.7842\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492507\tvalid's Opt metric: 0.783991\n",
      "[200]\tvalid's binary_logloss: 0.491903\tvalid's Opt metric: 0.784259\n",
      "[300]\tvalid's binary_logloss: 0.491835\tvalid's Opt metric: 0.784379\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid's binary_logloss: 0.491744\tvalid's Opt metric: 0.784259\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492023\tvalid's Opt metric: 0.784379\n",
      "[200]\tvalid's binary_logloss: 0.490714\tvalid's Opt metric: 0.784915\n",
      "[300]\tvalid's binary_logloss: 0.490614\tvalid's Opt metric: 0.785063\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid's binary_logloss: 0.490511\tvalid's Opt metric: 0.784944\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491792\tvalid's Opt metric: 0.783902\n",
      "[200]\tvalid's binary_logloss: 0.490925\tvalid's Opt metric: 0.784438\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid's binary_logloss: 0.491012\tvalid's Opt metric: 0.784944\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492462\tvalid's Opt metric: 0.783962\n",
      "[200]\tvalid's binary_logloss: 0.491527\tvalid's Opt metric: 0.783932\n",
      "[300]\tvalid's binary_logloss: 0.491684\tvalid's Opt metric: 0.783902\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid's binary_logloss: 0.491467\tvalid's Opt metric: 0.78414\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493554\tvalid's Opt metric: 0.783336\n",
      "[200]\tvalid's binary_logloss: 0.491656\tvalid's Opt metric: 0.784021\n",
      "[300]\tvalid's binary_logloss: 0.491097\tvalid's Opt metric: 0.784259\n",
      "[400]\tvalid's binary_logloss: 0.490769\tvalid's Opt metric: 0.784498\n",
      "Early stopping, best iteration is:\n",
      "[388]\tvalid's binary_logloss: 0.490766\tvalid's Opt metric: 0.784766\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491906\tvalid's Opt metric: 0.784021\n",
      "[200]\tvalid's binary_logloss: 0.490684\tvalid's Opt metric: 0.784557\n",
      "[300]\tvalid's binary_logloss: 0.490494\tvalid's Opt metric: 0.784766\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid's binary_logloss: 0.490719\tvalid's Opt metric: 0.784974\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492102\tvalid's Opt metric: 0.783932\n",
      "[200]\tvalid's binary_logloss: 0.491268\tvalid's Opt metric: 0.783902\n",
      "[300]\tvalid's binary_logloss: 0.490964\tvalid's Opt metric: 0.784289\n",
      "[400]\tvalid's binary_logloss: 0.491307\tvalid's Opt metric: 0.784527\n",
      "Early stopping, best iteration is:\n",
      "[322]\tvalid's binary_logloss: 0.490839\tvalid's Opt metric: 0.784766\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492216\tvalid's Opt metric: 0.783962\n",
      "[200]\tvalid's binary_logloss: 0.491331\tvalid's Opt metric: 0.78414\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid's binary_logloss: 0.491506\tvalid's Opt metric: 0.784617\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493172\tvalid's Opt metric: 0.783538\n",
      "[200]\tvalid's binary_logloss: 0.492414\tvalid's Opt metric: 0.783925\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid's binary_logloss: 0.49246\tvalid's Opt metric: 0.784253\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49434\tvalid's Opt metric: 0.783628\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid's binary_logloss: 0.494524\tvalid's Opt metric: 0.783747\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493161\tvalid's Opt metric: 0.783032\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid's binary_logloss: 0.496318\tvalid's Opt metric: 0.78327\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491461\tvalid's Opt metric: 0.783628\n",
      "[200]\tvalid's binary_logloss: 0.490418\tvalid's Opt metric: 0.783836\n",
      "[300]\tvalid's binary_logloss: 0.489831\tvalid's Opt metric: 0.784521\n",
      "[400]\tvalid's binary_logloss: 0.489919\tvalid's Opt metric: 0.784164\n",
      "Early stopping, best iteration is:\n",
      "[310]\tvalid's binary_logloss: 0.48979\tvalid's Opt metric: 0.784521\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 1301.4582657814026\n",
      "Blending: Optimization starts with equal weights and score 0.783474086691363\n",
      "Blending, iter 0: score = 0.7840696580229414, weights = [0.         0.13559583 0.86440414]\n",
      "Blending, iter 1: score = 0.7840696580229414, weights = [0.         0.13559583 0.86440414]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 499.54 seconds.\n",
      "oof_pred:\n",
      "array([[0.2595406 ],\n",
      "       [0.18275736],\n",
      "       [0.3596874 ],\n",
      "       [0.1988297 ],\n",
      "       [0.29199678],\n",
      "       [0.21189779],\n",
      "       [0.11155388],\n",
      "       [0.2494873 ],\n",
      "       [0.38937715],\n",
      "       [0.0859002 ]], dtype=float32)\n",
      "Shape = (167906, 1)\n",
      "CPU times: user 28min 37s, sys: 10.6 s, total: 28min 48s\n",
      "Wall time: 8min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "automl = TabularAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'n_jobs': N_THREADS})\n",
    "oof_pred = automl.fit_predict(tr_data, roles = roles)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-fortune",
   "metadata": {
    "papermill": {
     "duration": 0.133616,
     "end_time": "2021-04-24T12:37:52.834805",
     "exception": false,
     "start_time": "2021-04-24T12:37:52.701189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4. Predict to validation data and check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "textile-construction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T12:37:53.130304Z",
     "iopub.status.busy": "2021-04-24T12:37:53.118608Z",
     "iopub.status.idle": "2021-04-24T12:37:56.550643Z",
     "shell.execute_reply": "2021-04-24T12:37:56.549774Z"
    },
    "papermill": {
     "duration": 3.582469,
     "end_time": "2021-04-24T12:37:56.550845",
     "exception": false,
     "start_time": "2021-04-24T12:37:52.968376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test data:\n",
      "array([[0.1685951 ],\n",
      "       [0.09836732],\n",
      "       [0.08909526],\n",
      "       [0.13764949],\n",
      "       [0.20773   ],\n",
      "       [0.12484172],\n",
      "       [0.08959515],\n",
      "       [0.1992942 ],\n",
      "       [0.14634766],\n",
      "       [0.16506152]], dtype=float32)\n",
      "Shape = (41977, 1)\n",
      "Check scores...\n",
      "OOF score: 0.7840696580229414\n",
      "VALID score: 0.7839054720442147\n",
      "CPU times: user 8.91 s, sys: 15 ms, total: 8.92 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(te_data)\n",
    "print('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n",
    "\n",
    "print('Check scores...')\n",
    "print('OOF score: {}'.format(acc_score(tr_data[TARGET].values, oof_pred.data[:, 0])))\n",
    "print('VALID score: {}'.format(acc_score(te_data[TARGET].values, test_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-collectible",
   "metadata": {
    "papermill": {
     "duration": 0.146349,
     "end_time": "2021-04-24T12:37:56.833547",
     "exception": false,
     "start_time": "2021-04-24T12:37:56.687198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Score for `TabularAutoML` is 78.41% accuracy for OOF preds and 78.39% accuracy for validation preds in 8 minutes time. \n",
    "\n",
    "## Step 5. Create AutoML with time utilization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-nothing",
   "metadata": {
    "papermill": {
     "duration": 0.133786,
     "end_time": "2021-04-24T12:37:57.110892",
     "exception": false,
     "start_time": "2021-04-24T12:37:56.977106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below we are going to create specific AutoML preset for TIMEOUT utilization (try to spend it as much as possible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "concerned-peeing",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-24T12:37:57.395869Z",
     "iopub.status.busy": "2021-04-24T12:37:57.390914Z",
     "iopub.status.idle": "2021-04-24T13:02:29.180926Z",
     "shell.execute_reply": "2021-04-24T13:02:29.181580Z"
    },
    "papermill": {
     "duration": 1471.936963,
     "end_time": "2021-04-24T13:02:29.182088",
     "exception": false,
     "start_time": "2021-04-24T12:37:57.245125",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current random state: {'reader_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 4, 'random_state': 42}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 1799.9946620464325 seconds\n",
      "- cpus: 4 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (167906, 48)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 1767.5967831611633 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7826514204037878\n",
      "Linear model: C = 5e-05 score = 0.7830683104043833\n",
      "Linear model: C = 0.0001 score = 0.7829491989756417\n",
      "Linear model: C = 0.0005 score = 0.7830087546900125\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827938417557547\n",
      "Linear model: C = 5e-05 score = 0.783061850451148\n",
      "Linear model: C = 0.0001 score = 0.7835085316101367\n",
      "Linear model: C = 0.0005 score = 0.7836872040737322\n",
      "Linear model: C = 0.001 score = 0.7834489741222715\n",
      "Linear model: C = 0.005 score = 0.7834191953783389\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827938417557547\n",
      "Linear model: C = 5e-05 score = 0.7829129567314851\n",
      "Linear model: C = 0.0001 score = 0.7828533992436199\n",
      "Linear model: C = 0.0005 score = 0.782704505523957\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7826747267800244\n",
      "Linear model: C = 5e-05 score = 0.7826747267800244\n",
      "Linear model: C = 0.0001 score = 0.7825258330603615\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827342842678896\n",
      "Linear model: C = 5e-05 score = 0.7833298591465412\n",
      "Linear model: C = 0.0001 score = 0.7832703016586761\n",
      "Linear model: C = 0.0005 score = 0.783061850451148\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 1741.5868926048279\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491542\tvalid's Opt metric: 0.783962\n",
      "[200]\tvalid's binary_logloss: 0.490526\tvalid's Opt metric: 0.784676\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid's binary_logloss: 0.490586\tvalid's Opt metric: 0.784915\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493289\tvalid's Opt metric: 0.783777\n",
      "[200]\tvalid's binary_logloss: 0.492131\tvalid's Opt metric: 0.783955\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid's binary_logloss: 0.492314\tvalid's Opt metric: 0.784551\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494174\tvalid's Opt metric: 0.783449\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid's binary_logloss: 0.494709\tvalid's Opt metric: 0.783955\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492752\tvalid's Opt metric: 0.78327\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid's binary_logloss: 0.494802\tvalid's Opt metric: 0.783538\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49121\tvalid's Opt metric: 0.783777\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's binary_logloss: 0.491942\tvalid's Opt metric: 0.783836\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 1284.052366232872 secs\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492032\tvalid's Opt metric: 0.783515\n",
      "[200]\tvalid's binary_logloss: 0.491693\tvalid's Opt metric: 0.783753\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid's binary_logloss: 0.491548\tvalid's Opt metric: 0.784706\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491804\tvalid's Opt metric: 0.784081\n",
      "[200]\tvalid's binary_logloss: 0.490951\tvalid's Opt metric: 0.784855\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid's binary_logloss: 0.490935\tvalid's Opt metric: 0.785123\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492165\tvalid's Opt metric: 0.783843\n",
      "[200]\tvalid's binary_logloss: 0.491472\tvalid's Opt metric: 0.784379\n",
      "[300]\tvalid's binary_logloss: 0.491074\tvalid's Opt metric: 0.784438\n",
      "[400]\tvalid's binary_logloss: 0.491133\tvalid's Opt metric: 0.784468\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid's binary_logloss: 0.491164\tvalid's Opt metric: 0.784795\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492863\tvalid's Opt metric: 0.783545\n",
      "[200]\tvalid's binary_logloss: 0.491582\tvalid's Opt metric: 0.784408\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid's binary_logloss: 0.491804\tvalid's Opt metric: 0.784557\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492205\tvalid's Opt metric: 0.783843\n",
      "[200]\tvalid's binary_logloss: 0.491845\tvalid's Opt metric: 0.784289\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid's binary_logloss: 0.491367\tvalid's Opt metric: 0.784468\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492536\tvalid's Opt metric: 0.783307\n",
      "[200]\tvalid's binary_logloss: 0.491021\tvalid's Opt metric: 0.784706\n",
      "[300]\tvalid's binary_logloss: 0.490421\tvalid's Opt metric: 0.784915\n",
      "[400]\tvalid's binary_logloss: 0.490464\tvalid's Opt metric: 0.78548\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid's binary_logloss: 0.490267\tvalid's Opt metric: 0.785123\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492789\tvalid's Opt metric: 0.783426\n",
      "[200]\tvalid's binary_logloss: 0.491384\tvalid's Opt metric: 0.7842\n",
      "[300]\tvalid's binary_logloss: 0.490973\tvalid's Opt metric: 0.784557\n",
      "[400]\tvalid's binary_logloss: 0.490744\tvalid's Opt metric: 0.784408\n",
      "[500]\tvalid's binary_logloss: 0.490504\tvalid's Opt metric: 0.784915\n",
      "[600]\tvalid's binary_logloss: 0.490561\tvalid's Opt metric: 0.784587\n",
      "Early stopping, best iteration is:\n",
      "[501]\tvalid's binary_logloss: 0.490494\tvalid's Opt metric: 0.785063\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492243\tvalid's Opt metric: 0.784051\n",
      "[200]\tvalid's binary_logloss: 0.492101\tvalid's Opt metric: 0.784349\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid's binary_logloss: 0.491728\tvalid's Opt metric: 0.784051\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492686\tvalid's Opt metric: 0.783753\n",
      "[200]\tvalid's binary_logloss: 0.49115\tvalid's Opt metric: 0.784319\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid's binary_logloss: 0.491268\tvalid's Opt metric: 0.784527\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492305\tvalid's Opt metric: 0.784051\n",
      "[200]\tvalid's binary_logloss: 0.492013\tvalid's Opt metric: 0.784349\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid's binary_logloss: 0.491909\tvalid's Opt metric: 0.784676\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492224\tvalid's Opt metric: 0.784319\n",
      "[200]\tvalid's binary_logloss: 0.491502\tvalid's Opt metric: 0.784468\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid's binary_logloss: 0.491831\tvalid's Opt metric: 0.784885\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492321\tvalid's Opt metric: 0.783843\n",
      "[200]\tvalid's binary_logloss: 0.490741\tvalid's Opt metric: 0.78417\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid's binary_logloss: 0.491206\tvalid's Opt metric: 0.784408\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493923\tvalid's Opt metric: 0.783307\n",
      "[200]\tvalid's binary_logloss: 0.492125\tvalid's Opt metric: 0.783783\n",
      "[300]\tvalid's binary_logloss: 0.491497\tvalid's Opt metric: 0.783843\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid's binary_logloss: 0.491952\tvalid's Opt metric: 0.784081\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49246\tvalid's Opt metric: 0.783872\n",
      "[200]\tvalid's binary_logloss: 0.491587\tvalid's Opt metric: 0.784408\n",
      "[300]\tvalid's binary_logloss: 0.491683\tvalid's Opt metric: 0.784527\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid's binary_logloss: 0.491488\tvalid's Opt metric: 0.784498\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491827\tvalid's Opt metric: 0.784111\n",
      "[200]\tvalid's binary_logloss: 0.491135\tvalid's Opt metric: 0.784795\n",
      "[300]\tvalid's binary_logloss: 0.491295\tvalid's Opt metric: 0.784587\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid's binary_logloss: 0.491024\tvalid's Opt metric: 0.784676\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492072\tvalid's Opt metric: 0.784051\n",
      "[200]\tvalid's binary_logloss: 0.49096\tvalid's Opt metric: 0.78423\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid's binary_logloss: 0.490929\tvalid's Opt metric: 0.783902\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492127\tvalid's Opt metric: 0.783991\n",
      "[200]\tvalid's binary_logloss: 0.490846\tvalid's Opt metric: 0.784825\n",
      "[300]\tvalid's binary_logloss: 0.490577\tvalid's Opt metric: 0.784766\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid's binary_logloss: 0.490783\tvalid's Opt metric: 0.784944\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493763\tvalid's Opt metric: 0.783366\n",
      "[200]\tvalid's binary_logloss: 0.491794\tvalid's Opt metric: 0.783932\n",
      "[300]\tvalid's binary_logloss: 0.491173\tvalid's Opt metric: 0.784379\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid's binary_logloss: 0.49137\tvalid's Opt metric: 0.784468\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491914\tvalid's Opt metric: 0.783575\n",
      "[200]\tvalid's binary_logloss: 0.491139\tvalid's Opt metric: 0.783813\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid's binary_logloss: 0.491077\tvalid's Opt metric: 0.784349\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492193\tvalid's Opt metric: 0.784468\n",
      "[200]\tvalid's binary_logloss: 0.491346\tvalid's Opt metric: 0.785063\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid's binary_logloss: 0.49145\tvalid's Opt metric: 0.785153\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492153\tvalid's Opt metric: 0.78423\n",
      "[200]\tvalid's binary_logloss: 0.491761\tvalid's Opt metric: 0.784587\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid's binary_logloss: 0.491992\tvalid's Opt metric: 0.784795\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493801\tvalid's Opt metric: 0.784253\n",
      "[200]\tvalid's binary_logloss: 0.494143\tvalid's Opt metric: 0.783955\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid's binary_logloss: 0.493823\tvalid's Opt metric: 0.784313\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493894\tvalid's Opt metric: 0.783419\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid's binary_logloss: 0.494314\tvalid's Opt metric: 0.783806\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492469\tvalid's Opt metric: 0.782705\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid's binary_logloss: 0.495496\tvalid's Opt metric: 0.783598\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491373\tvalid's Opt metric: 0.783479\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid's binary_logloss: 0.492473\tvalid's Opt metric: 0.784164\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 1301.558964252472\n",
      "Blending: Optimization starts with equal weights and score 0.7835991566709944\n",
      "Blending, iter 0: score = 0.784051790882994, weights = [0.         0.87378263 0.12621735]\n",
      "Blending, iter 1: score = 0.784051790882994, weights = [0.         0.87378263 0.12621735]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 499.47 seconds.\n",
      "Current random state: {'reader_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 4, 'random_state': 43}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 1300.494434595108 seconds\n",
      "- cpus: 4 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (167906, 48)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 1267.6375050544739 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827407539753439\n",
      "Linear model: C = 5e-05 score = 0.7830980882615687\n",
      "Linear model: C = 0.0001 score = 0.7830385325471979\n",
      "Linear model: C = 0.0005 score = 0.7832171996903103\n",
      "Linear model: C = 0.001 score = 0.7830385325471979\n",
      "Linear model: C = 0.005 score = 0.7830980882615687\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827342842678896\n",
      "Linear model: C = 5e-05 score = 0.7829725142193502\n",
      "Linear model: C = 0.0001 score = 0.7827640630118221\n",
      "Linear model: C = 0.0005 score = 0.7828236204996873\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.782704505523957\n",
      "Linear model: C = 5e-05 score = 0.782704505523957\n",
      "Linear model: C = 0.0001 score = 0.783061850451148\n",
      "Linear model: C = 0.0005 score = 0.7826747267800244\n",
      "Linear model: C = 0.001 score = 0.782704505523957\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827342842678896\n",
      "Linear model: C = 5e-05 score = 0.7828236204996873\n",
      "Linear model: C = 0.0001 score = 0.7824662755724964\n",
      "Linear model: C = 0.0005 score = 0.7823769393406986\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7828236204996873\n",
      "Linear model: C = 5e-05 score = 0.7831511866829457\n",
      "Linear model: C = 0.0001 score = 0.7831214079390131\n",
      "Linear model: C = 0.0005 score = 0.7828831779875525\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 1237.7008838653564\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.496529\tvalid's Opt metric: 0.783575\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid's binary_logloss: 0.4967\tvalid's Opt metric: 0.783694\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492987\tvalid's Opt metric: 0.783962\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid's binary_logloss: 0.493384\tvalid's Opt metric: 0.784081\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491423\tvalid's Opt metric: 0.783211\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid's binary_logloss: 0.492748\tvalid's Opt metric: 0.783538\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492385\tvalid's Opt metric: 0.783866\n",
      "[200]\tvalid's binary_logloss: 0.491894\tvalid's Opt metric: 0.784164\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid's binary_logloss: 0.491618\tvalid's Opt metric: 0.784313\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493892\tvalid's Opt metric: 0.783449\n",
      "[200]\tvalid's binary_logloss: 0.493105\tvalid's Opt metric: 0.783449\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid's binary_logloss: 0.493312\tvalid's Opt metric: 0.784045\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493916\tvalid's Opt metric: 0.78327\n",
      "[200]\tvalid's binary_logloss: 0.493464\tvalid's Opt metric: 0.782913\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid's binary_logloss: 0.493842\tvalid's Opt metric: 0.783687\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 821.3445768594743 secs\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492647\tvalid's Opt metric: 0.783575\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid's binary_logloss: 0.492891\tvalid's Opt metric: 0.783843\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492588\tvalid's Opt metric: 0.783366\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid's binary_logloss: 0.492788\tvalid's Opt metric: 0.783843\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493094\tvalid's Opt metric: 0.783634\n",
      "[200]\tvalid's binary_logloss: 0.492093\tvalid's Opt metric: 0.783902\n",
      "[300]\tvalid's binary_logloss: 0.492193\tvalid's Opt metric: 0.784408\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid's binary_logloss: 0.491929\tvalid's Opt metric: 0.784408\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493159\tvalid's Opt metric: 0.783634\n",
      "[200]\tvalid's binary_logloss: 0.492287\tvalid's Opt metric: 0.783932\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid's binary_logloss: 0.492551\tvalid's Opt metric: 0.784527\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493796\tvalid's Opt metric: 0.783396\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid's binary_logloss: 0.493908\tvalid's Opt metric: 0.783932\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493278\tvalid's Opt metric: 0.783783\n",
      "[200]\tvalid's binary_logloss: 0.492277\tvalid's Opt metric: 0.783545\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's binary_logloss: 0.492661\tvalid's Opt metric: 0.784259\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493522\tvalid's Opt metric: 0.783604\n",
      "[200]\tvalid's binary_logloss: 0.492077\tvalid's Opt metric: 0.78414\n",
      "[300]\tvalid's binary_logloss: 0.491862\tvalid's Opt metric: 0.784408\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid's binary_logloss: 0.49204\tvalid's Opt metric: 0.784587\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493591\tvalid's Opt metric: 0.783664\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid's binary_logloss: 0.493729\tvalid's Opt metric: 0.784021\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493307\tvalid's Opt metric: 0.783485\n",
      "[200]\tvalid's binary_logloss: 0.491951\tvalid's Opt metric: 0.783545\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid's binary_logloss: 0.492398\tvalid's Opt metric: 0.783843\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493292\tvalid's Opt metric: 0.783098\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid's binary_logloss: 0.493945\tvalid's Opt metric: 0.783723\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494981\tvalid's Opt metric: 0.783307\n",
      "[200]\tvalid's binary_logloss: 0.492924\tvalid's Opt metric: 0.7842\n",
      "[300]\tvalid's binary_logloss: 0.492499\tvalid's Opt metric: 0.784319\n",
      "[400]\tvalid's binary_logloss: 0.492427\tvalid's Opt metric: 0.784438\n",
      "Early stopping, best iteration is:\n",
      "[364]\tvalid's binary_logloss: 0.492438\tvalid's Opt metric: 0.784498\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492897\tvalid's Opt metric: 0.783813\n",
      "[200]\tvalid's binary_logloss: 0.492716\tvalid's Opt metric: 0.783902\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid's binary_logloss: 0.492786\tvalid's Opt metric: 0.784081\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493329\tvalid's Opt metric: 0.784051\n",
      "[200]\tvalid's binary_logloss: 0.492741\tvalid's Opt metric: 0.783455\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid's binary_logloss: 0.493329\tvalid's Opt metric: 0.784051\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494416\tvalid's Opt metric: 0.783247\n",
      "[200]\tvalid's binary_logloss: 0.492665\tvalid's Opt metric: 0.784527\n",
      "[300]\tvalid's binary_logloss: 0.492266\tvalid's Opt metric: 0.784527\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid's binary_logloss: 0.492384\tvalid's Opt metric: 0.784676\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494014\tvalid's Opt metric: 0.783455\n",
      "[200]\tvalid's binary_logloss: 0.492326\tvalid's Opt metric: 0.784289\n",
      "[300]\tvalid's binary_logloss: 0.491924\tvalid's Opt metric: 0.78414\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid's binary_logloss: 0.492019\tvalid's Opt metric: 0.784468\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494618\tvalid's Opt metric: 0.783217\n",
      "[200]\tvalid's binary_logloss: 0.492494\tvalid's Opt metric: 0.78423\n",
      "[300]\tvalid's binary_logloss: 0.492183\tvalid's Opt metric: 0.784468\n",
      "[400]\tvalid's binary_logloss: 0.492022\tvalid's Opt metric: 0.784438\n",
      "[500]\tvalid's binary_logloss: 0.492136\tvalid's Opt metric: 0.784438\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid's binary_logloss: 0.491967\tvalid's Opt metric: 0.784647\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493311\tvalid's Opt metric: 0.783664\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid's binary_logloss: 0.49373\tvalid's Opt metric: 0.784021\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494596\tvalid's Opt metric: 0.783158\n",
      "[200]\tvalid's binary_logloss: 0.492583\tvalid's Opt metric: 0.784438\n",
      "[300]\tvalid's binary_logloss: 0.492184\tvalid's Opt metric: 0.784766\n",
      "[400]\tvalid's binary_logloss: 0.492063\tvalid's Opt metric: 0.784795\n",
      "Early stopping, best iteration is:\n",
      "[354]\tvalid's binary_logloss: 0.492065\tvalid's Opt metric: 0.784915\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492862\tvalid's Opt metric: 0.783783\n",
      "[200]\tvalid's binary_logloss: 0.492233\tvalid's Opt metric: 0.78417\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid's binary_logloss: 0.492193\tvalid's Opt metric: 0.783902\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493007\tvalid's Opt metric: 0.783932\n",
      "[200]\tvalid's binary_logloss: 0.492329\tvalid's Opt metric: 0.783753\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid's binary_logloss: 0.492806\tvalid's Opt metric: 0.784259\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493903\tvalid's Opt metric: 0.783962\n",
      "[200]\tvalid's binary_logloss: 0.492674\tvalid's Opt metric: 0.78417\n",
      "[300]\tvalid's binary_logloss: 0.492669\tvalid's Opt metric: 0.784259\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid's binary_logloss: 0.492541\tvalid's Opt metric: 0.784468\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49395\tvalid's Opt metric: 0.783545\n",
      "[200]\tvalid's binary_logloss: 0.492344\tvalid's Opt metric: 0.784438\n",
      "[300]\tvalid's binary_logloss: 0.492147\tvalid's Opt metric: 0.784349\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid's binary_logloss: 0.492077\tvalid's Opt metric: 0.784408\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494528\tvalid's Opt metric: 0.783485\n",
      "[200]\tvalid's binary_logloss: 0.49257\tvalid's Opt metric: 0.783991\n",
      "[300]\tvalid's binary_logloss: 0.492113\tvalid's Opt metric: 0.784527\n",
      "[400]\tvalid's binary_logloss: 0.49182\tvalid's Opt metric: 0.784944\n",
      "[500]\tvalid's binary_logloss: 0.491901\tvalid's Opt metric: 0.785034\n",
      "Early stopping, best iteration is:\n",
      "[430]\tvalid's binary_logloss: 0.491869\tvalid's Opt metric: 0.785242\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493368\tvalid's Opt metric: 0.783694\n",
      "[200]\tvalid's binary_logloss: 0.492362\tvalid's Opt metric: 0.783813\n",
      "[300]\tvalid's binary_logloss: 0.492309\tvalid's Opt metric: 0.784259\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid's binary_logloss: 0.492355\tvalid's Opt metric: 0.784468\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493296\tvalid's Opt metric: 0.783813\n",
      "[200]\tvalid's binary_logloss: 0.492224\tvalid's Opt metric: 0.783783\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid's binary_logloss: 0.493082\tvalid's Opt metric: 0.784111\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493264\tvalid's Opt metric: 0.783634\n",
      "[200]\tvalid's binary_logloss: 0.492732\tvalid's Opt metric: 0.78423\n",
      "[300]\tvalid's binary_logloss: 0.492811\tvalid's Opt metric: 0.783455\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's binary_logloss: 0.492755\tvalid's Opt metric: 0.784319\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493598\tvalid's Opt metric: 0.783545\n",
      "[200]\tvalid's binary_logloss: 0.492355\tvalid's Opt metric: 0.783962\n",
      "[300]\tvalid's binary_logloss: 0.492253\tvalid's Opt metric: 0.783872\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid's binary_logloss: 0.492243\tvalid's Opt metric: 0.784319\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492624\tvalid's Opt metric: 0.783389\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid's binary_logloss: 0.493171\tvalid's Opt metric: 0.783449\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493697\tvalid's Opt metric: 0.783241\n",
      "[200]\tvalid's binary_logloss: 0.493329\tvalid's Opt metric: 0.783806\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid's binary_logloss: 0.492671\tvalid's Opt metric: 0.78336\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494706\tvalid's Opt metric: 0.783032\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid's binary_logloss: 0.495712\tvalid's Opt metric: 0.78336\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494565\tvalid's Opt metric: 0.782734\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's binary_logloss: 0.495528\tvalid's Opt metric: 0.78327\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 808.5707104206085\n",
      "Blending: Optimization starts with equal weights and score 0.7832775481519422\n",
      "Blending, iter 0: score = 0.783694448084047, weights = [0.         0.9389133  0.06108671]\n",
      "Blending, iter 1: score = 0.783694448084047, weights = [0.         0.9389133  0.06108671]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 492.98 seconds.\n",
      "Current random state: {'reader_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 4, 'random_state': 44}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 807.4758131504059 seconds\n",
      "- cpus: 4 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (167906, 48)\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 806.9144804477692 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827407539753439\n",
      "Linear model: C = 5e-05 score = 0.7826514204037878\n",
      "Linear model: C = 0.0001 score = 0.782591864689417\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827342842678896\n",
      "Linear model: C = 5e-05 score = 0.7825556118042941\n",
      "Linear model: C = 0.0001 score = 0.7825853905482266\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827640630118221\n",
      "Linear model: C = 5e-05 score = 0.7826747267800244\n",
      "Linear model: C = 0.0001 score = 0.7825556118042941\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827342842678896\n",
      "Linear model: C = 5e-05 score = 0.7828236204996873\n",
      "Linear model: C = 0.0001 score = 0.7828533992436199\n",
      "Linear model: C = 0.0005 score = 0.7825853905482266\n",
      "Linear model: C = 0.001 score = 0.7825853905482266\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827342842678896\n",
      "Linear model: C = 5e-05 score = 0.7828236204996873\n",
      "Linear model: C = 0.0001 score = 0.7826449480360919\n",
      "Linear model: C = 0.0005 score = 0.7827342842678896\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 785.286988735199\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497339\tvalid's Opt metric: 0.783545\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid's binary_logloss: 0.498222\tvalid's Opt metric: 0.783932\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497878\tvalid's Opt metric: 0.783723\n",
      "[200]\tvalid's binary_logloss: 0.496826\tvalid's Opt metric: 0.783604\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid's binary_logloss: 0.497861\tvalid's Opt metric: 0.783902\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497861\tvalid's Opt metric: 0.783657\n",
      "[200]\tvalid's binary_logloss: 0.497083\tvalid's Opt metric: 0.783866\n",
      "[300]\tvalid's binary_logloss: 0.497168\tvalid's Opt metric: 0.784313\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid's binary_logloss: 0.496931\tvalid's Opt metric: 0.784104\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49392\tvalid's Opt metric: 0.783092\n",
      "[200]\tvalid's binary_logloss: 0.493098\tvalid's Opt metric: 0.782764\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid's binary_logloss: 0.493512\tvalid's Opt metric: 0.783389\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.495683\tvalid's Opt metric: 0.78327\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid's binary_logloss: 0.496413\tvalid's Opt metric: 0.783509\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.496465\tvalid's Opt metric: 0.783241\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid's binary_logloss: 0.496515\tvalid's Opt metric: 0.783241\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 364.7181050062179 secs\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.498502\tvalid's Opt metric: 0.783247\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid's binary_logloss: 0.499557\tvalid's Opt metric: 0.783515\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.4974\tvalid's Opt metric: 0.783723\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid's binary_logloss: 0.497535\tvalid's Opt metric: 0.783843\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.498668\tvalid's Opt metric: 0.783307\n",
      "[200]\tvalid's binary_logloss: 0.497772\tvalid's Opt metric: 0.7828\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid's binary_logloss: 0.498074\tvalid's Opt metric: 0.783396\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49823\tvalid's Opt metric: 0.783307\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid's binary_logloss: 0.498606\tvalid's Opt metric: 0.783545\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497833\tvalid's Opt metric: 0.782622\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid's binary_logloss: 0.498967\tvalid's Opt metric: 0.783307\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.498416\tvalid's Opt metric: 0.783068\n",
      "[200]\tvalid's binary_logloss: 0.496867\tvalid's Opt metric: 0.783515\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid's binary_logloss: 0.497154\tvalid's Opt metric: 0.783932\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.499123\tvalid's Opt metric: 0.782979\n",
      "[200]\tvalid's binary_logloss: 0.497295\tvalid's Opt metric: 0.783307\n",
      "[300]\tvalid's binary_logloss: 0.497054\tvalid's Opt metric: 0.783396\n",
      "[400]\tvalid's binary_logloss: 0.496792\tvalid's Opt metric: 0.783694\n",
      "[500]\tvalid's binary_logloss: 0.496784\tvalid's Opt metric: 0.783485\n",
      "Early stopping, best iteration is:\n",
      "[408]\tvalid's binary_logloss: 0.49679\tvalid's Opt metric: 0.783783\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497854\tvalid's Opt metric: 0.783366\n",
      "[200]\tvalid's binary_logloss: 0.497213\tvalid's Opt metric: 0.783158\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid's binary_logloss: 0.497025\tvalid's Opt metric: 0.783723\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.498296\tvalid's Opt metric: 0.783277\n",
      "[200]\tvalid's binary_logloss: 0.496732\tvalid's Opt metric: 0.783426\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's binary_logloss: 0.497419\tvalid's Opt metric: 0.783723\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497774\tvalid's Opt metric: 0.782503\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid's binary_logloss: 0.499234\tvalid's Opt metric: 0.783158\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497534\tvalid's Opt metric: 0.783366\n",
      "[200]\tvalid's binary_logloss: 0.496336\tvalid's Opt metric: 0.783277\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid's binary_logloss: 0.49667\tvalid's Opt metric: 0.783962\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497613\tvalid's Opt metric: 0.783277\n",
      "[200]\tvalid's binary_logloss: 0.496294\tvalid's Opt metric: 0.783277\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid's binary_logloss: 0.49641\tvalid's Opt metric: 0.783932\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497241\tvalid's Opt metric: 0.782949\n",
      "[200]\tvalid's binary_logloss: 0.496554\tvalid's Opt metric: 0.782503\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid's binary_logloss: 0.496909\tvalid's Opt metric: 0.783485\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497576\tvalid's Opt metric: 0.782979\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid's binary_logloss: 0.498735\tvalid's Opt metric: 0.783426\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497969\tvalid's Opt metric: 0.783307\n",
      "[200]\tvalid's binary_logloss: 0.497129\tvalid's Opt metric: 0.7828\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid's binary_logloss: 0.49767\tvalid's Opt metric: 0.783515\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.500718\tvalid's Opt metric: 0.783009\n",
      "[200]\tvalid's binary_logloss: 0.498469\tvalid's Opt metric: 0.783098\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid's binary_logloss: 0.498773\tvalid's Opt metric: 0.783277\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497537\tvalid's Opt metric: 0.783158\n",
      "[200]\tvalid's binary_logloss: 0.496743\tvalid's Opt metric: 0.783336\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid's binary_logloss: 0.496831\tvalid's Opt metric: 0.783902\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497178\tvalid's Opt metric: 0.783575\n",
      "[200]\tvalid's binary_logloss: 0.496432\tvalid's Opt metric: 0.783604\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid's binary_logloss: 0.496233\tvalid's Opt metric: 0.783366\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.498041\tvalid's Opt metric: 0.783426\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid's binary_logloss: 0.4988\tvalid's Opt metric: 0.783545\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.499531\tvalid's Opt metric: 0.78289\n",
      "[200]\tvalid's binary_logloss: 0.497309\tvalid's Opt metric: 0.783396\n",
      "[300]\tvalid's binary_logloss: 0.496778\tvalid's Opt metric: 0.783604\n",
      "[400]\tvalid's binary_logloss: 0.496363\tvalid's Opt metric: 0.783455\n",
      "Early stopping, best iteration is:\n",
      "[367]\tvalid's binary_logloss: 0.496407\tvalid's Opt metric: 0.783723\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49756\tvalid's Opt metric: 0.783545\n",
      "[200]\tvalid's binary_logloss: 0.496183\tvalid's Opt metric: 0.783991\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid's binary_logloss: 0.49618\tvalid's Opt metric: 0.78417\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497301\tvalid's Opt metric: 0.783753\n",
      "[200]\tvalid's binary_logloss: 0.496146\tvalid's Opt metric: 0.783723\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid's binary_logloss: 0.496596\tvalid's Opt metric: 0.783991\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497293\tvalid's Opt metric: 0.783485\n",
      "[200]\tvalid's binary_logloss: 0.496211\tvalid's Opt metric: 0.783634\n",
      "[300]\tvalid's binary_logloss: 0.496022\tvalid's Opt metric: 0.783545\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid's binary_logloss: 0.496162\tvalid's Opt metric: 0.783902\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497745\tvalid's Opt metric: 0.783515\n",
      "[200]\tvalid's binary_logloss: 0.496235\tvalid's Opt metric: 0.783366\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid's binary_logloss: 0.497191\tvalid's Opt metric: 0.783664\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497575\tvalid's Opt metric: 0.783039\n",
      "[200]\tvalid's binary_logloss: 0.496783\tvalid's Opt metric: 0.783485\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid's binary_logloss: 0.496746\tvalid's Opt metric: 0.783723\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.496902\tvalid's Opt metric: 0.783634\n",
      "[200]\tvalid's binary_logloss: 0.496009\tvalid's Opt metric: 0.783545\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid's binary_logloss: 0.495949\tvalid's Opt metric: 0.783843\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.497327\tvalid's Opt metric: 0.783985\n",
      "[200]\tvalid's binary_logloss: 0.496527\tvalid's Opt metric: 0.784045\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's binary_logloss: 0.496653\tvalid's Opt metric: 0.784134\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.493368\tvalid's Opt metric: 0.783211\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid's binary_logloss: 0.493756\tvalid's Opt metric: 0.78336\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494526\tvalid's Opt metric: 0.783389\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid's binary_logloss: 0.495223\tvalid's Opt metric: 0.783657\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.496276\tvalid's Opt metric: 0.782764\n",
      "[200]\tvalid's binary_logloss: 0.495322\tvalid's Opt metric: 0.78336\n",
      "[300]\tvalid's binary_logloss: 0.495428\tvalid's Opt metric: 0.783121\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid's binary_logloss: 0.495144\tvalid's Opt metric: 0.783538\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 330.1450641155243\n",
      "Blending: Optimization starts with equal weights and score 0.7830631424725739\n",
      "Blending, iter 0: score = 0.7837063595106786, weights = [0.         0.35801193 0.64198804]\n",
      "Blending, iter 1: score = 0.7837063595106786, weights = [0.         0.35801193 0.64198804]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 478.36 seconds.\n",
      "Blending: Optimization starts with equal weights and score 0.7836527580908366\n",
      "Blending, iter 0: score = 0.7840994365895203, weights = [1. 0. 0.]\n",
      "Blending, iter 1: score = 0.7840994365895203, weights = [1. 0. 0.]\n",
      "No score update. Terminated\n",
      "oof_pred:\n",
      "array([[0.26871923],\n",
      "       [0.17974125],\n",
      "       [0.34537908],\n",
      "       [0.20874865],\n",
      "       [0.3075699 ],\n",
      "       [0.19762397],\n",
      "       [0.10538377],\n",
      "       [0.26535326],\n",
      "       [0.39949894],\n",
      "       [0.0759992 ]], dtype=float32)\n",
      "Shape = (167906, 1)\n",
      "CPU times: user 1h 26min 8s, sys: 30.1 s, total: 1h 26min 38s\n",
      "Wall time: 24min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "automl = TabularUtilizedAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'n_jobs': N_THREADS})\n",
    "oof_pred = automl.fit_predict(tr_data, roles = roles)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-crest",
   "metadata": {
    "papermill": {
     "duration": 0.37454,
     "end_time": "2021-04-24T13:02:30.020245",
     "exception": false,
     "start_time": "2021-04-24T13:02:29.645705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 6. Predict to validation data and check scores for utilized automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proof-principal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T13:02:30.777078Z",
     "iopub.status.busy": "2021-04-24T13:02:30.776127Z",
     "iopub.status.idle": "2021-04-24T13:02:34.146830Z",
     "shell.execute_reply": "2021-04-24T13:02:34.146241Z"
    },
    "papermill": {
     "duration": 3.753688,
     "end_time": "2021-04-24T13:02:34.146989",
     "exception": false,
     "start_time": "2021-04-24T13:02:30.393301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test data:\n",
      "array([[0.16277397],\n",
      "       [0.10110205],\n",
      "       [0.09686656],\n",
      "       [0.13924266],\n",
      "       [0.20566234],\n",
      "       [0.13305603],\n",
      "       [0.08988725],\n",
      "       [0.22741953],\n",
      "       [0.14805262],\n",
      "       [0.18487623]], dtype=float32)\n",
      "Shape = (41977, 1)\n",
      "Check scores...\n",
      "OOF score: 0.7840994365895203\n",
      "VALID score: 0.7838816494747124\n",
      "CPU times: user 8.44 s, sys: 3.08 ms, total: 8.44 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(te_data)\n",
    "print('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n",
    "\n",
    "print('Check scores...')\n",
    "print('OOF score: {}'.format(acc_score(tr_data[TARGET].values, oof_pred.data[:, 0])))\n",
    "print('VALID score: {}'.format(acc_score(te_data[TARGET].values, test_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-billion",
   "metadata": {
    "papermill": {
     "duration": 0.375241,
     "end_time": "2021-04-24T13:02:34.906337",
     "exception": false,
     "start_time": "2021-04-24T13:02:34.531096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Score for `TabularUtilizedAutoML` is 78.41% accuracy for OOF preds and 78.39% accuracy for validation preds in 23.5 minutes. As the validation score is better for `TabularAutoML` for this case, we choose it for final model retrain on full train dataset.\n",
    "\n",
    "## Step 7. Train on full data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "respective-bottle",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-24T13:02:35.686591Z",
     "iopub.status.busy": "2021-04-24T13:02:35.685925Z",
     "iopub.status.idle": "2021-04-24T13:12:11.989346Z",
     "shell.execute_reply": "2021-04-24T13:12:11.988544Z"
    },
    "papermill": {
     "duration": 576.707344,
     "end_time": "2021-04-24T13:12:11.989544",
     "exception": false,
     "start_time": "2021-04-24T13:02:35.282200",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start automl preset with listed constraints:\n",
      "- time: 1800 seconds\n",
      "- cpus: 4 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (209883, 48)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 1765.2139074802399 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.782690520999595\n",
      "Linear model: C = 5e-05 score = 0.7831431498201396\n",
      "Linear model: C = 0.0001 score = 0.7830478595421302\n",
      "Linear model: C = 0.0005 score = 0.7829525692641208\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827858112776044\n",
      "Linear model: C = 5e-05 score = 0.7833813755151631\n",
      "Linear model: C = 0.0001 score = 0.7835957786406842\n",
      "Linear model: C = 0.0005 score = 0.7835243109321771\n",
      "Linear model: C = 0.001 score = 0.7833813755151631\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.782690520999595\n",
      "Linear model: C = 5e-05 score = 0.7828096338471068\n",
      "Linear model: C = 0.0001 score = 0.7823570050265621\n",
      "Linear model: C = 0.0005 score = 0.7825714081520833\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7828521059653135\n",
      "Linear model: C = 5e-05 score = 0.7829473985134362\n",
      "Linear model: C = 0.0001 score = 0.7828044596912521\n",
      "Linear model: C = 0.0005 score = 0.7825424051839146\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = 0.7827806365542215\n",
      "Linear model: C = 5e-05 score = 0.7830903373356204\n",
      "Linear model: C = 0.0001 score = 0.783114160472651\n",
      "Linear model: C = 0.0005 score = 0.7832570992948351\n",
      "Linear model: C = 0.001 score = 0.7831856298837431\n",
      "Linear model: C = 0.005 score = 0.7831618067467124\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 1731.746535539627\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.494854\tvalid's Opt metric: 0.783358\n",
      "[200]\tvalid's binary_logloss: 0.493463\tvalid's Opt metric: 0.783977\n",
      "[300]\tvalid's binary_logloss: 0.493509\tvalid's Opt metric: 0.783977\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid's binary_logloss: 0.493374\tvalid's Opt metric: 0.783715\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491188\tvalid's Opt metric: 0.783215\n",
      "[200]\tvalid's binary_logloss: 0.490182\tvalid's Opt metric: 0.783358\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid's binary_logloss: 0.490408\tvalid's Opt metric: 0.783786\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490533\tvalid's Opt metric: 0.783763\n",
      "[200]\tvalid's binary_logloss: 0.489659\tvalid's Opt metric: 0.784191\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid's binary_logloss: 0.489581\tvalid's Opt metric: 0.784549\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49155\tvalid's Opt metric: 0.783548\n",
      "[200]\tvalid's binary_logloss: 0.490662\tvalid's Opt metric: 0.784191\n",
      "[300]\tvalid's binary_logloss: 0.490614\tvalid's Opt metric: 0.784048\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid's binary_logloss: 0.490522\tvalid's Opt metric: 0.784525\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492627\tvalid's Opt metric: 0.783805\n",
      "[200]\tvalid's binary_logloss: 0.491764\tvalid's Opt metric: 0.783805\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's binary_logloss: 0.491879\tvalid's Opt metric: 0.784186\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492086\tvalid's Opt metric: 0.784186\n",
      "[200]\tvalid's binary_logloss: 0.491415\tvalid's Opt metric: 0.784305\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid's binary_logloss: 0.491559\tvalid's Opt metric: 0.784496\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 1146.9607076644897 secs\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491018\tvalid's Opt metric: 0.782857\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid's binary_logloss: 0.492703\tvalid's Opt metric: 0.7835\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49065\tvalid's Opt metric: 0.783643\n",
      "[200]\tvalid's binary_logloss: 0.490058\tvalid's Opt metric: 0.782833\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid's binary_logloss: 0.49065\tvalid's Opt metric: 0.783643\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491934\tvalid's Opt metric: 0.783334\n",
      "[200]\tvalid's binary_logloss: 0.490973\tvalid's Opt metric: 0.783262\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid's binary_logloss: 0.49161\tvalid's Opt metric: 0.7835\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49154\tvalid's Opt metric: 0.783405\n",
      "[200]\tvalid's binary_logloss: 0.490471\tvalid's Opt metric: 0.783191\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's binary_logloss: 0.490862\tvalid's Opt metric: 0.783596\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491556\tvalid's Opt metric: 0.782667\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid's binary_logloss: 0.494584\tvalid's Opt metric: 0.783477\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492033\tvalid's Opt metric: 0.783405\n",
      "[200]\tvalid's binary_logloss: 0.490598\tvalid's Opt metric: 0.783572\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid's binary_logloss: 0.490775\tvalid's Opt metric: 0.784025\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492153\tvalid's Opt metric: 0.7835\n",
      "[200]\tvalid's binary_logloss: 0.490872\tvalid's Opt metric: 0.783453\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid's binary_logloss: 0.491261\tvalid's Opt metric: 0.783763\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491337\tvalid's Opt metric: 0.782619\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid's binary_logloss: 0.492905\tvalid's Opt metric: 0.783691\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491555\tvalid's Opt metric: 0.783453\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid's binary_logloss: 0.492047\tvalid's Opt metric: 0.783548\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49156\tvalid's Opt metric: 0.783143\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid's binary_logloss: 0.491641\tvalid's Opt metric: 0.783739\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490948\tvalid's Opt metric: 0.783953\n",
      "[200]\tvalid's binary_logloss: 0.489338\tvalid's Opt metric: 0.783882\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid's binary_logloss: 0.490279\tvalid's Opt metric: 0.784239\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49111\tvalid's Opt metric: 0.783977\n",
      "[200]\tvalid's binary_logloss: 0.48976\tvalid's Opt metric: 0.784001\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid's binary_logloss: 0.490777\tvalid's Opt metric: 0.784096\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491047\tvalid's Opt metric: 0.782905\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid's binary_logloss: 0.492515\tvalid's Opt metric: 0.783763\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491342\tvalid's Opt metric: 0.783739\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid's binary_logloss: 0.491356\tvalid's Opt metric: 0.783858\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.49109\tvalid's Opt metric: 0.783381\n",
      "[200]\tvalid's binary_logloss: 0.490213\tvalid's Opt metric: 0.783381\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid's binary_logloss: 0.490176\tvalid's Opt metric: 0.783596\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491189\tvalid's Opt metric: 0.783739\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's binary_logloss: 0.492164\tvalid's Opt metric: 0.783763\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490868\tvalid's Opt metric: 0.783739\n",
      "[200]\tvalid's binary_logloss: 0.489349\tvalid's Opt metric: 0.7835\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid's binary_logloss: 0.490373\tvalid's Opt metric: 0.783977\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490951\tvalid's Opt metric: 0.782905\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid's binary_logloss: 0.491307\tvalid's Opt metric: 0.783429\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491221\tvalid's Opt metric: 0.782929\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid's binary_logloss: 0.492997\tvalid's Opt metric: 0.783405\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491134\tvalid's Opt metric: 0.783643\n",
      "[200]\tvalid's binary_logloss: 0.490477\tvalid's Opt metric: 0.783191\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid's binary_logloss: 0.490819\tvalid's Opt metric: 0.784025\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491148\tvalid's Opt metric: 0.783596\n",
      "[200]\tvalid's binary_logloss: 0.489628\tvalid's Opt metric: 0.783929\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's binary_logloss: 0.490265\tvalid's Opt metric: 0.784144\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490892\tvalid's Opt metric: 0.783834\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid's binary_logloss: 0.491094\tvalid's Opt metric: 0.784263\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490677\tvalid's Opt metric: 0.783524\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid's binary_logloss: 0.491213\tvalid's Opt metric: 0.78381\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.490318\tvalid's Opt metric: 0.78362\n",
      "[200]\tvalid's binary_logloss: 0.489991\tvalid's Opt metric: 0.783215\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid's binary_logloss: 0.489849\tvalid's Opt metric: 0.783929\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491109\tvalid's Opt metric: 0.78381\n",
      "[200]\tvalid's binary_logloss: 0.490848\tvalid's Opt metric: 0.784573\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid's binary_logloss: 0.490587\tvalid's Opt metric: 0.784239\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.491397\tvalid's Opt metric: 0.783424\n",
      "[200]\tvalid's binary_logloss: 0.491601\tvalid's Opt metric: 0.783162\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid's binary_logloss: 0.491341\tvalid's Opt metric: 0.783591\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.492297\tvalid's Opt metric: 0.784305\n",
      "[200]\tvalid's binary_logloss: 0.492038\tvalid's Opt metric: 0.784615\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid's binary_logloss: 0.491991\tvalid's Opt metric: 0.784496\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 1224.9967596530914\n",
      "Blending: Optimization starts with equal weights and score 0.7836175392957029\n",
      "Blending, iter 0: score = 0.7841464053782345, weights = [0.         0.8061888  0.19381121]\n",
      "Blending, iter 1: score = 0.7841464053782345, weights = [0.         0.8061888  0.19381121]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 576.28 seconds.\n",
      "oof_pred:\n",
      "array([[0.29929996],\n",
      "       [0.44504032],\n",
      "       [0.2874392 ],\n",
      "       [0.5077995 ],\n",
      "       [0.4820975 ],\n",
      "       [0.2818896 ],\n",
      "       [0.20042169],\n",
      "       [0.14129181],\n",
      "       [0.25775227],\n",
      "       [0.46595973]], dtype=float32)\n",
      "Shape = (209883, 1)\n",
      "CPU times: user 32min 58s, sys: 10.7 s, total: 33min 9s\n",
      "Wall time: 9min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "automl = TabularAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'n_jobs': N_THREADS})\n",
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-retreat",
   "metadata": {
    "papermill": {
     "duration": 0.447303,
     "end_time": "2021-04-24T13:12:12.893750",
     "exception": false,
     "start_time": "2021-04-24T13:12:12.446447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 8. Predict for test data and check OOF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "turned-happening",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T13:12:13.805346Z",
     "iopub.status.busy": "2021-04-24T13:12:13.804356Z",
     "iopub.status.idle": "2021-04-24T13:12:16.231280Z",
     "shell.execute_reply": "2021-04-24T13:12:16.230733Z"
    },
    "papermill": {
     "duration": 2.887821,
     "end_time": "2021-04-24T13:12:16.231427",
     "exception": false,
     "start_time": "2021-04-24T13:12:13.343606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test data:\n",
      "array([[0.24235617],\n",
      "       [0.3815322 ],\n",
      "       [0.08559681],\n",
      "       [0.52745163],\n",
      "       [0.37283877],\n",
      "       [0.19917758],\n",
      "       [0.37359193],\n",
      "       [0.5434454 ],\n",
      "       [0.2988817 ],\n",
      "       [0.31130612]], dtype=float32)\n",
      "Shape = (23271, 1)\n",
      "Check scores...\n",
      "OOF score: 0.7841464053782345\n",
      "CPU times: user 6.57 s, sys: 3.98 ms, total: 6.58 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(test_data)\n",
    "print('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n",
    "\n",
    "print('Check scores...')\n",
    "print('OOF score: {}'.format(acc_score(train_data[TARGET].values, oof_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-atlas",
   "metadata": {
    "papermill": {
     "duration": 0.454756,
     "end_time": "2021-04-24T13:12:17.133454",
     "exception": false,
     "start_time": "2021-04-24T13:12:16.678698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 9. Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "suited-factory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T13:12:18.039643Z",
     "iopub.status.busy": "2021-04-24T13:12:18.038651Z",
     "iopub.status.idle": "2021-04-24T13:12:18.089962Z",
     "shell.execute_reply": "2021-04-24T13:12:18.088912Z"
    },
    "papermill": {
     "duration": 0.507972,
     "end_time": "2021-04-24T13:12:18.090136",
     "exception": false,
     "start_time": "2021-04-24T13:12:17.582164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission[TARGET] = (test_pred.data[:, 0] > 0.5).astype(int)\n",
    "submission.to_csv('automl_utilized.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "split-springer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T13:12:19.056313Z",
     "iopub.status.busy": "2021-04-24T13:12:19.055417Z",
     "iopub.status.idle": "2021-04-24T13:12:19.060340Z",
     "shell.execute_reply": "2021-04-24T13:12:19.059730Z"
    },
    "papermill": {
     "duration": 0.467374,
     "end_time": "2021-04-24T13:12:19.060475",
     "exception": false,
     "start_time": "2021-04-24T13:12:18.593101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23266</th>\n",
       "      <td>23267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23267</th>\n",
       "      <td>23268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23268</th>\n",
       "      <td>23269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23269</th>\n",
       "      <td>23270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23270</th>\n",
       "      <td>23271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23271 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  loan_default\n",
       "0          1             0\n",
       "1          2             0\n",
       "2          3             0\n",
       "3          4             1\n",
       "4          5             0\n",
       "...      ...           ...\n",
       "23266  23267             0\n",
       "23267  23268             0\n",
       "23268  23269             0\n",
       "23269  23270             0\n",
       "23270  23271             0\n",
       "\n",
       "[23271 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-mineral",
   "metadata": {
    "papermill": {
     "duration": 0.460577,
     "end_time": "2021-04-24T13:12:19.966721",
     "exception": false,
     "start_time": "2021-04-24T13:12:19.506144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 10. Feature importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "welcome-discovery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-24T13:12:20.881423Z",
     "iopub.status.busy": "2021-04-24T13:12:20.880748Z",
     "iopub.status.idle": "2021-04-24T13:12:21.697249Z",
     "shell.execute_reply": "2021-04-24T13:12:21.697786Z"
    },
    "papermill": {
     "duration": 1.278896,
     "end_time": "2021-04-24T13:12:21.697974",
     "exception": false,
     "start_time": "2021-04-24T13:12:20.419078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 3.99 ms, total: 164 ms\n",
      "Wall time: 178 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Feature'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fast feature importances calculation\n",
    "fast_fi = automl.get_feature_scores('fast')\n",
    "fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-processor",
   "metadata": {
    "papermill": {
     "duration": 0.454966,
     "end_time": "2021-04-24T13:12:22.609328",
     "exception": false,
     "start_time": "2021-04-24T13:12:22.154362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2617.05251,
   "end_time": "2021-04-24T13:12:25.573978",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-24T12:28:48.521468",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
